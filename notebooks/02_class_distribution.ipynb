{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Class Distribution Analysis\n",
    "\n",
    "**Story 1.2** — Compute per-class point counts and per-scene object statistics to calibrate loss weights and DBSCAN parameters.\n",
    "\n",
    "**Acceptance criteria:**\n",
    "- Per-class point count table across all frames\n",
    "- Per-scene breakdown showing which classes appear in which scenes\n",
    "- Background vs labeled point ratios\n",
    "- Loss weights calibrated from actual class frequencies\n",
    "- Validation scene selected (most diverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/airbus_hackathon\"\n",
    "DATA_DIR = f\"{DRIVE_BASE}/data\"\n",
    "PROJECT_DIR = f\"{DRIVE_BASE}/project\"\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJECT_DIR, 'src'))\n",
    "sys.path.insert(0, os.path.join(PROJECT_DIR, 'airbus_hackathon_toolkit'))\n",
    "\n",
    "from lidar_utils import load_h5_data, get_unique_poses, filter_by_pose, spherical_to_local_cartesian\n",
    "from config import CLASS_COLORS, CLASS_NAMES, NUM_CLASSES, SCENE_FILES\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rgb_to_class(df_frame):\n",
    "    \"\"\"Map RGB labels to class IDs. 0 = background.\"\"\"\n",
    "    class_ids = np.zeros(len(df_frame), dtype=np.int64)\n",
    "    for (r, g, b), class_id in CLASS_COLORS.items():\n",
    "        mask = (\n",
    "            (df_frame[\"r\"].values == r) &\n",
    "            (df_frame[\"g\"].values == g) &\n",
    "            (df_frame[\"b\"].values == b)\n",
    "        )\n",
    "        class_ids[mask] = class_id\n",
    "    return class_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scan All 998 Frames — Per-Class Point Counts\n",
    "\n",
    "This takes a few minutes. We process scene by scene, frame by frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Collect stats: one row per frame\n",
    "frame_stats = []\n",
    "\n",
    "for scene_file in SCENE_FILES:\n",
    "    path = os.path.join(DATA_DIR, scene_file)\n",
    "    scene_name = scene_file.replace(\".h5\", \"\")\n",
    "    \n",
    "    print(f\"\\nProcessing {scene_file}...\")\n",
    "    df = load_h5_data(path)\n",
    "    poses = get_unique_poses(df)\n",
    "    \n",
    "    for idx in tqdm(range(len(poses)), desc=scene_name):\n",
    "        frame = filter_by_pose(df, poses.iloc[idx])\n",
    "        \n",
    "        # Filter valid points\n",
    "        valid = frame[frame[\"distance_cm\"] > 0]\n",
    "        \n",
    "        # Map to classes\n",
    "        class_ids = map_rgb_to_class(valid)\n",
    "        \n",
    "        # Count per class\n",
    "        row = {\n",
    "            \"scene\": scene_name,\n",
    "            \"frame_idx\": idx,\n",
    "            \"total_points\": len(valid),\n",
    "            \"ego_x\": poses.iloc[idx][\"ego_x\"],\n",
    "            \"ego_y\": poses.iloc[idx][\"ego_y\"],\n",
    "            \"ego_z\": poses.iloc[idx][\"ego_z\"],\n",
    "            \"ego_yaw\": poses.iloc[idx][\"ego_yaw\"],\n",
    "        }\n",
    "        for cid in range(NUM_CLASSES):\n",
    "            row[CLASS_NAMES[cid]] = int((class_ids == cid).sum())\n",
    "        \n",
    "        frame_stats.append(row)\n",
    "    \n",
    "    # Free memory\n",
    "    del df\n",
    "\n",
    "stats_df = pd.DataFrame(frame_stats)\n",
    "print(f\"\\nDone! {len(stats_df)} frames analyzed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total points per class across all frames\n",
    "class_cols = [CLASS_NAMES[i] for i in range(NUM_CLASSES)]\n",
    "totals = stats_df[class_cols].sum()\n",
    "grand_total = totals.sum()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GLOBAL CLASS DISTRIBUTION (all 998 frames)\")\n",
    "print(\"=\" * 60)\n",
    "for cname in class_cols:\n",
    "    count = totals[cname]\n",
    "    pct = count / grand_total * 100\n",
    "    print(f\"  {cname:15s}: {count:>12,} points ({pct:>6.3f}%)\")\n",
    "print(f\"  {'TOTAL':15s}: {grand_total:>12,} points\")\n",
    "\n",
    "# Obstacle vs background ratio\n",
    "bg = totals[\"background\"]\n",
    "obs = grand_total - bg\n",
    "print(f\"\\nBackground: {bg/grand_total*100:.2f}%\")\n",
    "print(f\"Obstacles:  {obs/grand_total*100:.2f}%\")\n",
    "print(f\"Ratio bg/obs: {bg/obs:.0f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart — obstacle classes only (exclude background for readability)\n",
    "obstacle_cols = [CLASS_NAMES[i] for i in range(1, NUM_CLASSES)]\n",
    "obstacle_totals = totals[obstacle_cols]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Absolute counts\n",
    "colors = ['#2617B4', '#B18430', '#815161', '#428409']  # Airbus class colors\n",
    "axes[0].bar(obstacle_cols, obstacle_totals.values, color=colors)\n",
    "axes[0].set_ylabel(\"Total Points\")\n",
    "axes[0].set_title(\"Total Points per Obstacle Class (all frames)\")\n",
    "for i, v in enumerate(obstacle_totals.values):\n",
    "    axes[0].text(i, v + v*0.02, f\"{v:,.0f}\", ha='center', fontsize=9)\n",
    "\n",
    "# Percentage of obstacle points\n",
    "obs_total = obstacle_totals.sum()\n",
    "obs_pct = obstacle_totals / obs_total * 100\n",
    "axes[1].bar(obstacle_cols, obs_pct.values, color=colors)\n",
    "axes[1].set_ylabel(\"% of Obstacle Points\")\n",
    "axes[1].set_title(\"Class Share Among Obstacles\")\n",
    "for i, v in enumerate(obs_pct.values):\n",
    "    axes[1].text(i, v + 0.5, f\"{v:.1f}%\", ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Per-Scene Breakdown — Which Classes Appear Where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-scene totals\n",
    "scene_totals = stats_df.groupby(\"scene\")[obstacle_cols].sum()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PER-SCENE OBSTACLE POINT COUNTS\")\n",
    "print(\"=\" * 80)\n",
    "print(scene_totals.to_string())\n",
    "\n",
    "# Which classes are present in each scene? (>0 points)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASS PRESENCE PER SCENE (X = present)\")\n",
    "print(\"=\" * 80)\n",
    "presence = (scene_totals > 0).replace({True: \"X\", False: \"-\"})\n",
    "print(presence.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of class distribution per scene\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Normalize per scene (percentage of obstacle points in that scene)\n",
    "scene_obs_total = scene_totals.sum(axis=1)\n",
    "scene_pct = scene_totals.div(scene_obs_total, axis=0) * 100\n",
    "scene_pct = scene_pct.fillna(0)\n",
    "\n",
    "im = ax.imshow(scene_pct.values, cmap='YlOrRd', aspect='auto')\n",
    "ax.set_xticks(range(len(obstacle_cols)))\n",
    "ax.set_xticklabels(obstacle_cols, rotation=45, ha='right')\n",
    "ax.set_yticks(range(len(scene_pct)))\n",
    "ax.set_yticklabels(scene_pct.index)\n",
    "ax.set_title(\"Class Distribution per Scene (% of obstacle points)\")\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(scene_pct)):\n",
    "    for j in range(len(obstacle_cols)):\n",
    "        val = scene_pct.values[i, j]\n",
    "        count = scene_totals.values[i, j]\n",
    "        text_color = 'white' if val > 50 else 'black'\n",
    "        ax.text(j, i, f\"{val:.0f}%\\n({count:,.0f})\", \n",
    "                ha='center', va='center', fontsize=8, color=text_color)\n",
    "\n",
    "plt.colorbar(im, label=\"% of obstacle points\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-Frame Analysis — Frames With/Without Obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many frames have each class?\n",
    "stats_df[\"has_obstacles\"] = (stats_df[obstacle_cols].sum(axis=1) > 0)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FRAME-LEVEL CLASS PRESENCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for cname in obstacle_cols:\n",
    "    n_frames = (stats_df[cname] > 0).sum()\n",
    "    pct = n_frames / len(stats_df) * 100\n",
    "    avg_pts = stats_df[stats_df[cname] > 0][cname].mean() if n_frames > 0 else 0\n",
    "    print(f\"  {cname:15s}: present in {n_frames:>4d}/{len(stats_df)} frames ({pct:.1f}%), \"\n",
    "          f\"avg {avg_pts:,.0f} pts when present\")\n",
    "\n",
    "n_with = stats_df[\"has_obstacles\"].sum()\n",
    "n_without = len(stats_df) - n_with\n",
    "print(f\"\\nFrames WITH obstacles:    {n_with} ({n_with/len(stats_df)*100:.1f}%)\")\n",
    "print(f\"Frames WITHOUT obstacles: {n_without} ({n_without/len(stats_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of obstacle point counts per frame (when obstacles present)\n",
    "frames_with_obs = stats_df[stats_df[\"has_obstacles\"]]\n",
    "frames_with_obs[\"total_obstacle_pts\"] = frames_with_obs[obstacle_cols].sum(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of total obstacle points per frame\n",
    "axes[0].hist(frames_with_obs[\"total_obstacle_pts\"], bins=50, color=\"steelblue\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Obstacle Points per Frame\")\n",
    "axes[0].set_ylabel(\"Number of Frames\")\n",
    "axes[0].set_title(\"Distribution of Obstacle Points per Frame\")\n",
    "axes[0].axvline(frames_with_obs[\"total_obstacle_pts\"].median(), \n",
    "                color='red', linestyle='--', label=f\"Median: {frames_with_obs['total_obstacle_pts'].median():.0f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Per-class box plot\n",
    "box_data = []\n",
    "box_labels = []\n",
    "for cname in obstacle_cols:\n",
    "    vals = stats_df[stats_df[cname] > 0][cname].values\n",
    "    if len(vals) > 0:\n",
    "        box_data.append(vals)\n",
    "        box_labels.append(cname)\n",
    "\n",
    "if box_data:\n",
    "    axes[1].boxplot(box_data, labels=box_labels)\n",
    "    axes[1].set_ylabel(\"Points per Frame\")\n",
    "    axes[1].set_title(\"Points per Frame by Class (when present)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scene Diversity Analysis — Select Validation Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score each scene by diversity:\n",
    "# - Number of distinct classes present\n",
    "# - Total obstacle points\n",
    "# - Balance between classes\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SCENE DIVERSITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "diversity_scores = []\n",
    "for scene in scene_totals.index:\n",
    "    row = scene_totals.loc[scene]\n",
    "    n_classes = (row > 0).sum()\n",
    "    total_obs = row.sum()\n",
    "    \n",
    "    # Shannon entropy as balance measure (higher = more balanced)\n",
    "    if total_obs > 0:\n",
    "        probs = row[row > 0].values / total_obs\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "    else:\n",
    "        entropy = 0\n",
    "    \n",
    "    diversity_scores.append({\n",
    "        \"scene\": scene,\n",
    "        \"n_classes\": n_classes,\n",
    "        \"total_obstacle_pts\": total_obs,\n",
    "        \"entropy\": entropy,\n",
    "        \"diversity_score\": n_classes * entropy,  # composite score\n",
    "    })\n",
    "\n",
    "div_df = pd.DataFrame(diversity_scores).sort_values(\"diversity_score\", ascending=False)\n",
    "print(div_df.to_string(index=False))\n",
    "\n",
    "best_val_scene = div_df.iloc[0][\"scene\"]\n",
    "print(f\"\\n>>> RECOMMENDED VALIDATION SCENE: {best_val_scene} <<<\")\n",
    "print(f\"    (highest diversity score = {div_df.iloc[0]['diversity_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calibrate Loss Weights\n",
    "\n",
    "Compute inverse frequency weights from the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute actual class frequencies\n",
    "total_per_class = stats_df[class_cols].sum()\n",
    "total_all = total_per_class.sum()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOSS WEIGHT CALIBRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Inverse frequency weighting\n",
    "# weight_i = total_all / (NUM_CLASSES * count_i)\n",
    "# Then normalize so background = 0.1 (we don't want to over-penalize bg errors)\n",
    "\n",
    "raw_weights = {}\n",
    "for i, cname in enumerate(class_cols):\n",
    "    count = total_per_class[cname]\n",
    "    if count > 0:\n",
    "        raw_weights[cname] = total_all / (NUM_CLASSES * count)\n",
    "    else:\n",
    "        raw_weights[cname] = 1.0  # default if class never appears\n",
    "\n",
    "# Normalize: set background to a fixed low value\n",
    "bg_weight = 0.1\n",
    "scale_factor = bg_weight / raw_weights[\"background\"]\n",
    "\n",
    "calibrated_weights = {}\n",
    "for cname in class_cols:\n",
    "    calibrated_weights[cname] = raw_weights[cname] * scale_factor\n",
    "\n",
    "print(\"\\nRaw inverse-frequency weights:\")\n",
    "for cname in class_cols:\n",
    "    freq = total_per_class[cname] / total_all * 100\n",
    "    print(f\"  {cname:15s}: freq={freq:>7.3f}%, raw_weight={raw_weights[cname]:.4f}\")\n",
    "\n",
    "print(\"\\nCalibrated weights (background pinned to 0.1):\")\n",
    "weight_list = []\n",
    "for cname in class_cols:\n",
    "    w = calibrated_weights[cname]\n",
    "    weight_list.append(round(w, 2))\n",
    "    print(f\"  {cname:15s}: {w:.2f}\")\n",
    "\n",
    "print(f\"\\n>>> COPY THIS TO config.py: <<<\")\n",
    "print(f'\"class_weights\": {weight_list},  # [bg, antenna, cable, pole, turbine]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the weights\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(class_cols, weight_list, \n",
    "              color=['gray', '#2617B4', '#B18430', '#815161', '#428409'])\n",
    "ax.set_ylabel(\"Loss Weight\")\n",
    "ax.set_title(\"Calibrated Class Weights for Cross-Entropy Loss\")\n",
    "for bar, w in zip(bars, weight_list):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            f\"{w:.2f}\", ha='center', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary & Config Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STORY 1.2 — SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset: {len(stats_df)} frames across {stats_df['scene'].nunique()} scenes\")\n",
    "print(f\"Total points: {total_all:,.0f}\")\n",
    "print(f\"Background ratio: {total_per_class['background']/total_all*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nObstacle class summary:\")\n",
    "for cname in obstacle_cols:\n",
    "    n_frames = (stats_df[cname] > 0).sum()\n",
    "    total = total_per_class[cname]\n",
    "    print(f\"  {cname:15s}: {total:>10,} pts across {n_frames:>4d} frames\")\n",
    "\n",
    "print(f\"\\n--- CONFIG UPDATES NEEDED ---\")\n",
    "print(f'val_scene: \"{best_val_scene}\"')\n",
    "print(f'class_weights: {weight_list}')\n",
    "print(f\"\\nUpdate these values in src/config.py before training!\")\n",
    "\n",
    "print(f\"\\n--- VALIDATION CHECKLIST ---\")\n",
    "checks = [\n",
    "    (\"Per-class point count table computed\", True),\n",
    "    (\"Per-scene breakdown with class presence\", True),\n",
    "    (\"Background vs labeled ratio computed\", True),\n",
    "    (\"Loss weights calibrated from data\", True),\n",
    "    (f\"Validation scene selected: {best_val_scene}\", True),\n",
    "]\n",
    "for desc, passed in checks:\n",
    "    print(f\"  [{'PASS' if passed else 'FAIL'}] {desc}\")\n",
    "\n",
    "print(f\"\\nStory 1.2 COMPLETE. Next: Story 1.3 — GT Bounding Box Reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stats DataFrame for later use\n",
    "output_path = os.path.join(DRIVE_BASE, \"outputs\", \"frame_stats.csv\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "stats_df.to_csv(output_path, index=False)\n",
    "print(f\"Frame stats saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
