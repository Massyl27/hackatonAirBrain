{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 — Interactive 3D Visualization (Plotly)\n",
    "\n",
    "Interactive 3D visualization of LiDAR point clouds with predicted bounding boxes.\n",
    "\n",
    "- Uses **Plotly** for browser-based 3D rendering (works in Colab)\n",
    "- Runs PointNetSegV4 inference on a single frame, then clusters + PCA bounding boxes\n",
    "- Background points are heavily subsampled (~15k) for performance; obstacle points are kept at higher density (~10k)\n",
    "- Bounding boxes are drawn as wireframes with class-specific colors\n",
    "- Rotate / zoom / pan with your mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install -q h5py scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os, time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import BallTree\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/airbus_hackathon\"\n",
    "INPUT_DIR = f\"{DRIVE_BASE}/data\"\n",
    "CKPT_V5 = f\"{DRIVE_BASE}/checkpoints_v5/best_model_v5.pt\"\n",
    "CKPT_V4 = f\"{DRIVE_BASE}/checkpoints_v4/best_model_v4.pt\"\n",
    "CKPT_PATH = CKPT_V5 if os.path.exists(CKPT_V5) else CKPT_V4\n",
    "SINGLE_SCENE = \"scene_8\"\n",
    "FRAME_INDEX = 30  # Which frame to visualize (0-indexed)\n",
    "\n",
    "# Display settings\n",
    "MAX_BG_POINTS = 15000     # subsample background\n",
    "MAX_OBS_POINTS = 10000    # keep more obstacle points\n",
    "POINT_SIZE = 1.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Checkpoint: {CKPT_PATH}\")\n",
    "print(f\"Scene: {SINGLE_SCENE}, frame: {FRAME_INDEX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config (v7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "IN_CHANNELS = 5\n",
    "CHUNK_SIZE = 65536\n",
    "\n",
    "CLASS_NAMES = {0: \"Background\", 1: \"Antenna\", 2: \"Cable\", 3: \"Electric Pole\", 4: \"Wind Turbine\"}\n",
    "CLASS_LABELS_CSV = {1: \"Antenna\", 2: \"Cable\", 3: \"Electric Pole\", 4: \"Wind Turbine\"}\n",
    "\n",
    "DBSCAN_PARAMS = {\n",
    "    1: {\"eps\": 2.0, \"min_samples\": 15},\n",
    "    2: {\"eps\": 5.0, \"min_samples\": 5},\n",
    "    3: {\"eps\": 2.0, \"min_samples\": 8},\n",
    "    4: {\"eps\": 5.0, \"min_samples\": 20},\n",
    "}\n",
    "CABLE_MERGE_ANGLE_DEG = 15.0\n",
    "CABLE_MERGE_GAP_M = 10.0\n",
    "\n",
    "CONFIDENCE_THRESHOLD_PER_CLASS = {1: 0.40, 2: 0.27, 3: 0.25, 4: 0.30}\n",
    "CONFIDENCE_THRESHOLD_DEFAULT = 0.3\n",
    "BOX_CONFIDENCE_THRESHOLD_PER_CLASS = {1: 0.70, 2: 0.55, 3: 0.45, 4: 0.60}\n",
    "BOX_CONFIDENCE_THRESHOLD_DEFAULT = 0.6\n",
    "\n",
    "MIN_POINTS_PER_BOX = {1: 15, 2: 3, 3: 5, 4: 15}\n",
    "MAX_DIM_PER_CLASS = {1: 200.0, 2: 400.0, 3: 100.0, 4: 250.0}\n",
    "NMS_IOU_THRESHOLD = 0.3\n",
    "\n",
    "# Colors for plotly (RGB strings)\n",
    "CLASS_COLORS_PLOTLY = {\n",
    "    0: 'rgb(180, 180, 180)',    # background — grey\n",
    "    1: 'rgb(38, 23, 180)',      # antenna — blue\n",
    "    2: 'rgb(177, 132, 47)',     # cable — gold\n",
    "    3: 'rgb(129, 81, 97)',      # electric pole — mauve\n",
    "    4: 'rgb(66, 132, 9)',       # wind turbine — green\n",
    "}\n",
    "BOX_COLORS_PLOTLY = {\n",
    "    1: 'rgb(38, 23, 230)',      # antenna — bright blue\n",
    "    2: 'rgb(220, 165, 60)',     # cable — bright gold\n",
    "    3: 'rgb(180, 100, 130)',    # electric pole — bright mauve\n",
    "    4: 'rgb(80, 180, 10)',      # wind turbine — bright green\n",
    "}\n",
    "\n",
    "print(\"Config loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMLP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bn=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, 1, bias=not bn)\n",
    "        self.bn = nn.BatchNorm1d(out_ch) if bn else None\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class PointNetSegV4(nn.Module):\n",
    "    \"\"\"PointNet v4 segmentation — multi-scale skips, ~1.88M params.\"\"\"\n",
    "    def __init__(self, in_channels=5, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.enc1 = SharedMLP(in_channels, 64)\n",
    "        self.enc2 = SharedMLP(64, 128)\n",
    "        self.enc3 = SharedMLP(128, 256)\n",
    "        self.enc4 = SharedMLP(256, 512)\n",
    "        self.enc5 = SharedMLP(512, 1024)\n",
    "        # 64+128+256+512+1024 = 1984\n",
    "        self.seg1 = SharedMLP(64 + 128 + 256 + 512 + 1024, 512)\n",
    "        self.seg2 = SharedMLP(512, 256)\n",
    "        self.seg3 = SharedMLP(256, 128)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.head = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.shape\n",
    "        x = x.transpose(1, 2)\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "        g = e5.max(dim=2, keepdim=True)[0].expand(-1, -1, N)\n",
    "        seg = torch.cat([e1, e2, e3, e4, g], dim=1)\n",
    "        seg = self.seg1(seg)\n",
    "        seg = self.dropout1(seg)\n",
    "        seg = self.seg2(seg)\n",
    "        seg = self.dropout2(seg)\n",
    "        seg = self.seg3(seg)\n",
    "        seg = self.head(seg)\n",
    "        return seg.transpose(1, 2)\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "model = PointNetSegV4(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES).to(device)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model loaded: {n_params:,} params\")\n",
    "if \"val_obstacle_miou\" in ckpt:\n",
    "    print(f\"Checkpoint epoch {ckpt.get('epoch', '?')}, val obstacle mIoU={ckpt['val_obstacle_miou']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 Reader + Inference + Clustering\n",
    "\n",
    "All pipeline functions inlined from `scripts/inference.py` (no external imports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HDF5 CHUNKED READER\n",
    "# ============================================================================\n",
    "\n",
    "def get_frame_boundaries(h5_path, dataset_name=\"lidar_points\", chunk_size=2_000_000):\n",
    "    \"\"\"Find frame boundaries by reading in chunks — vectorized with np.diff.\"\"\"\n",
    "    change_indices = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        n = ds.shape[0]\n",
    "        prev_last_pose = None\n",
    "        for offset in range(0, n, chunk_size):\n",
    "            end = min(offset + chunk_size, n)\n",
    "            chunk = ds[offset:end]\n",
    "            ex = chunk[\"ego_x\"]\n",
    "            ey = chunk[\"ego_y\"]\n",
    "            ez = chunk[\"ego_z\"]\n",
    "            eyaw = chunk[\"ego_yaw\"]\n",
    "            if prev_last_pose is not None:\n",
    "                cur_first = (int(ex[0]), int(ey[0]), int(ez[0]), int(eyaw[0]))\n",
    "                if cur_first != prev_last_pose:\n",
    "                    change_indices.append(offset)\n",
    "            changes = np.where(\n",
    "                (np.diff(ex) != 0) | (np.diff(ey) != 0) |\n",
    "                (np.diff(ez) != 0) | (np.diff(eyaw) != 0)\n",
    "            )[0] + 1\n",
    "            for c in changes:\n",
    "                change_indices.append(offset + int(c))\n",
    "            prev_last_pose = (int(ex[-1]), int(ey[-1]), int(ez[-1]), int(eyaw[-1]))\n",
    "            del chunk, ex, ey, ez, eyaw\n",
    "            gc.collect()\n",
    "\n",
    "    starts = [0] + change_indices\n",
    "    ends = change_indices + [n]\n",
    "    frames = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        for s, e in zip(starts, ends):\n",
    "            row = ds[s]\n",
    "            frames.append((s, e, int(row[\"ego_x\"]), int(row[\"ego_y\"]),\n",
    "                           int(row[\"ego_z\"]), int(row[\"ego_yaw\"])))\n",
    "    return frames\n",
    "\n",
    "\n",
    "def read_frame_for_inference(h5_path, start, end, dataset_name=\"lidar_points\"):\n",
    "    \"\"\"Read a single frame and compute features for inference.\n",
    "\n",
    "    Returns:\n",
    "        xyz_m: (N, 3) float32 — local cartesian coordinates in meters\n",
    "        features: (N, 5) float32 — [x, y, z, reflectivity_norm, distance_norm]\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        chunk = f[dataset_name][start:end]\n",
    "\n",
    "    valid = chunk[chunk[\"distance_cm\"] > 0]\n",
    "    del chunk\n",
    "\n",
    "    dist_m = valid[\"distance_cm\"].astype(np.float64) / 100.0\n",
    "    az_rad = np.radians(valid[\"azimuth_raw\"].astype(np.float64) / 100.0)\n",
    "    el_rad = np.radians(valid[\"elevation_raw\"].astype(np.float64) / 100.0)\n",
    "\n",
    "    cos_el = np.cos(el_rad)\n",
    "    x = dist_m * cos_el * np.cos(az_rad)\n",
    "    y = -dist_m * cos_el * np.sin(az_rad)\n",
    "    z = dist_m * np.sin(el_rad)\n",
    "\n",
    "    xyz = np.column_stack((x, y, z)).astype(np.float32)\n",
    "    refl_norm = (valid[\"reflectivity\"].astype(np.float32) / 255.0).reshape(-1, 1)\n",
    "    dist_norm = (dist_m.astype(np.float32) / 300.0).reshape(-1, 1)\n",
    "\n",
    "    features = np.concatenate([xyz, refl_norm, dist_norm], axis=1)  # (N, 5)\n",
    "\n",
    "    del valid, dist_m, az_rad, el_rad, cos_el, x, y, z\n",
    "    return xyz, features\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CHUNKED INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_frame(model, features_np, device, chunk_size=65536,\n",
    "                  confidence_threshold=None):\n",
    "    \"\"\"Run inference on a full frame, chunked to avoid OOM.\n",
    "\n",
    "    Returns:\n",
    "        predictions: (N,) numpy int64 — class IDs [0..4]\n",
    "        confidences: (N,) numpy float32 — softmax probability of predicted class\n",
    "    \"\"\"\n",
    "    n = len(features_np)\n",
    "    predictions = np.zeros(n, dtype=np.int64)\n",
    "    confidences = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk = features_np[start:end]\n",
    "\n",
    "        # Pad to at least 128 points (BatchNorm needs reasonable batch stats)\n",
    "        pad_to = max(len(chunk), 128)\n",
    "        if len(chunk) < pad_to:\n",
    "            padded = np.zeros((pad_to, chunk.shape[1]), dtype=np.float32)\n",
    "            padded[:len(chunk)] = chunk\n",
    "        else:\n",
    "            padded = chunk\n",
    "\n",
    "        tensor = torch.from_numpy(padded).unsqueeze(0).to(device)  # (1, N, 5)\n",
    "        logits = model(tensor)  # (1, N, 5)\n",
    "        probs = F.softmax(logits[0, :len(chunk)], dim=-1)  # (N, 5)\n",
    "        conf, preds = probs.max(dim=-1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        conf = conf.cpu().numpy()\n",
    "\n",
    "        # Per-class confidence threshold: low-confidence obstacle predictions -> background\n",
    "        for cid in range(1, 5):\n",
    "            thresh = CONFIDENCE_THRESHOLD_PER_CLASS.get(cid, CONFIDENCE_THRESHOLD_DEFAULT)\n",
    "            low_conf = (preds == cid) & (conf < thresh)\n",
    "            preds[low_conf] = 0\n",
    "\n",
    "        predictions[start:end] = preds\n",
    "        confidences[start:end] = conf\n",
    "\n",
    "        del tensor, logits, probs, preds, conf\n",
    "    return predictions, confidences\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CLUSTERING + BOUNDING BOXES\n",
    "# ============================================================================\n",
    "\n",
    "def pca_oriented_bbox(points_m):\n",
    "    \"\"\"Compute PCA-oriented bounding box for a cluster of points.\"\"\"\n",
    "    center_xyz = points_m.mean(axis=0)\n",
    "    centered = points_m - center_xyz\n",
    "    cov = np.cov(centered.T)\n",
    "    if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "        mins = points_m.min(axis=0)\n",
    "        maxs = points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        mins = points_m.min(axis=0)\n",
    "        maxs = points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "    projected = centered @ eigenvectors\n",
    "    mins = projected.min(axis=0)\n",
    "    maxs = projected.max(axis=0)\n",
    "    dimensions = maxs - mins\n",
    "    box_center_pca = (mins + maxs) / 2.0\n",
    "    center_xyz = center_xyz + eigenvectors @ box_center_pca\n",
    "    axis1_xy = eigenvectors[:2, 0]\n",
    "    yaw = np.arctan2(axis1_xy[1], axis1_xy[0])\n",
    "    return {\"center_xyz\": center_xyz, \"dimensions\": dimensions, \"yaw\": float(yaw)}\n",
    "\n",
    "\n",
    "def cluster_class_points(points_m, class_id, max_points=10000):\n",
    "    \"\"\"DBSCAN clustering for a single class. Returns list of point arrays.\"\"\"\n",
    "    params = DBSCAN_PARAMS[class_id]\n",
    "    eps, min_samples = params[\"eps\"], params[\"min_samples\"]\n",
    "    if len(points_m) < min_samples:\n",
    "        return []\n",
    "\n",
    "    full_points = points_m\n",
    "    if len(points_m) > max_points:\n",
    "        idx = np.random.choice(len(points_m), max_points, replace=False)\n",
    "        points_m = points_m[idx]\n",
    "\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"ball_tree\").fit_predict(points_m)\n",
    "\n",
    "    if len(full_points) > max_points:\n",
    "        sampled_mask = labels >= 0\n",
    "        if sampled_mask.sum() == 0:\n",
    "            return []\n",
    "        tree = BallTree(points_m[sampled_mask])\n",
    "        _, indices = tree.query(full_points, k=1)\n",
    "        full_labels = labels[sampled_mask][indices.ravel()]\n",
    "        dists = np.linalg.norm(full_points - points_m[sampled_mask][indices.ravel()], axis=1)\n",
    "        full_labels[dists > eps * 2] = -1\n",
    "        labels = full_labels\n",
    "        points_m = full_points\n",
    "\n",
    "    clusters = []\n",
    "    for lbl in sorted(set(labels) - {-1}):\n",
    "        clusters.append(points_m[labels == lbl])\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def merge_cable_clusters(clusters):\n",
    "    \"\"\"Merge collinear cable clusters that are close together.\"\"\"\n",
    "    if len(clusters) <= 1:\n",
    "        return clusters\n",
    "    angle_thresh = np.radians(CABLE_MERGE_ANGLE_DEG)\n",
    "    gap_thresh = CABLE_MERGE_GAP_M\n",
    "    infos = []\n",
    "    for pts in clusters:\n",
    "        if len(pts) < 4:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        centered = pts - pts.mean(axis=0)\n",
    "        cov = np.cov(centered.T)\n",
    "        if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        try:\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "        except np.linalg.LinAlgError:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        axis1 = eigvecs[:, eigvals.argsort()[::-1][0]]\n",
    "        if axis1[0] < 0:\n",
    "            axis1 = -axis1\n",
    "        infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": axis1})\n",
    "\n",
    "    merged_flags = [False] * len(infos)\n",
    "    result = []\n",
    "    for i in range(len(infos)):\n",
    "        if merged_flags[i]:\n",
    "            continue\n",
    "        current = infos[i][\"points\"]\n",
    "        if infos[i][\"axis1\"] is not None:\n",
    "            for j in range(i + 1, len(infos)):\n",
    "                if merged_flags[j] or infos[j][\"axis1\"] is None:\n",
    "                    continue\n",
    "                dot = min(abs(np.dot(infos[i][\"axis1\"], infos[j][\"axis1\"])), 1.0)\n",
    "                if np.arccos(dot) > angle_thresh:\n",
    "                    continue\n",
    "                cdist = np.linalg.norm(infos[i][\"center\"] - infos[j][\"center\"])\n",
    "                ext_i = np.abs((infos[i][\"points\"] - infos[i][\"center\"]) @ infos[i][\"axis1\"]).max()\n",
    "                ext_j = np.abs((infos[j][\"points\"] - infos[j][\"center\"]) @ infos[j][\"axis1\"]).max()\n",
    "                if cdist - ext_i - ext_j <= gap_thresh:\n",
    "                    current = np.vstack([current, infos[j][\"points\"]])\n",
    "                    merged_flags[j] = True\n",
    "        result.append(current)\n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# POST-PROCESSING: SIZE FILTER + NMS + GEOMETRIC RECLASSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def filter_boxes(boxes):\n",
    "    \"\"\"Remove boxes that are too small (few points) or too large (over-merged).\"\"\"\n",
    "    filtered = []\n",
    "    for box in boxes:\n",
    "        cid = box[\"class_id\"]\n",
    "        if box[\"num_points\"] < MIN_POINTS_PER_BOX.get(cid, 3):\n",
    "            continue\n",
    "        max_dim = max(box[\"dimensions\"])\n",
    "        if max_dim > MAX_DIM_PER_CLASS.get(cid, 500.0):\n",
    "            continue\n",
    "        filtered.append(box)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def _box_iou_3d(box_a, box_b):\n",
    "    \"\"\"Approximate 3D IoU using axis-aligned overlap of PCA extents.\"\"\"\n",
    "    ca, da = box_a[\"center_xyz\"], box_a[\"dimensions\"]\n",
    "    cb, db = box_b[\"center_xyz\"], box_b[\"dimensions\"]\n",
    "    ha, hb = da / 2.0, db / 2.0\n",
    "    overlap = np.maximum(0, np.minimum(ca + ha, cb + hb) - np.maximum(ca - ha, cb - hb))\n",
    "    inter = overlap[0] * overlap[1] * overlap[2]\n",
    "    vol_a = da[0] * da[1] * da[2]\n",
    "    vol_b = db[0] * db[1] * db[2]\n",
    "    union = vol_a + vol_b - inter\n",
    "    if union <= 0:\n",
    "        return 0.0\n",
    "    return inter / union\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, iou_threshold=NMS_IOU_THRESHOLD):\n",
    "    \"\"\"Non-Maximum Suppression within each class. Keep box with more points.\"\"\"\n",
    "    if len(boxes) <= 1:\n",
    "        return boxes\n",
    "    by_class = {}\n",
    "    for box in boxes:\n",
    "        by_class.setdefault(box[\"class_id\"], []).append(box)\n",
    "    result = []\n",
    "    for cid, class_boxes in by_class.items():\n",
    "        class_boxes.sort(key=lambda b: b[\"num_points\"], reverse=True)\n",
    "        keep = []\n",
    "        suppressed = [False] * len(class_boxes)\n",
    "        for i in range(len(class_boxes)):\n",
    "            if suppressed[i]:\n",
    "                continue\n",
    "            keep.append(class_boxes[i])\n",
    "            for j in range(i + 1, len(class_boxes)):\n",
    "                if suppressed[j]:\n",
    "                    continue\n",
    "                iou = _box_iou_3d(class_boxes[i], class_boxes[j])\n",
    "                if iou > iou_threshold:\n",
    "                    suppressed[j] = True\n",
    "        result.extend(keep)\n",
    "    return result\n",
    "\n",
    "\n",
    "def reclassify_by_geometry(boxes):\n",
    "    \"\"\"Reclassify boxes based on geometric properties.\n",
    "\n",
    "    Fixes common model confusions:\n",
    "    - Antenna classified but shape is elongated + flat -> likely Cable\n",
    "    - Antenna classified but very large + many points -> likely Wind Turbine\n",
    "    \"\"\"\n",
    "    for box in boxes:\n",
    "        if box[\"class_id\"] != 1:  # only reclassify from antenna\n",
    "            continue\n",
    "        dims = box[\"dimensions\"]\n",
    "        sorted_dims = sorted(dims, reverse=True)  # [longest, middle, shortest]\n",
    "        longest, middle, shortest = sorted_dims\n",
    "\n",
    "        # Elongated + flat -> Cable\n",
    "        if middle > 0 and longest / middle > 5.0 and shortest < 1.0:\n",
    "            box[\"class_id\"] = 2\n",
    "            box[\"class_label\"] = CLASS_LABELS_CSV[2]\n",
    "\n",
    "        # Very large + many points -> Wind Turbine\n",
    "        elif longest > 15.0 and box[\"num_points\"] > 200:\n",
    "            box[\"class_id\"] = 4\n",
    "            box[\"class_label\"] = CLASS_LABELS_CSV[4]\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTIONS -> BOUNDING BOXES\n",
    "# ============================================================================\n",
    "\n",
    "def predictions_to_boxes(xyz_m, predictions, confidences=None,\n",
    "                         use_per_class_conf=True):\n",
    "    \"\"\"Convert per-point predictions to bounding boxes via DBSCAN + PCA + post-processing.\n",
    "\n",
    "    Pipeline: cluster -> PCA bbox -> geometric reclassification -> confidence filter -> size filter -> NMS\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    for cid in range(1, 5):\n",
    "        mask = predictions == cid\n",
    "        n_pts = mask.sum()\n",
    "        if n_pts == 0:\n",
    "            continue\n",
    "\n",
    "        class_points = xyz_m[mask]\n",
    "        class_conf = confidences[mask] if confidences is not None else None\n",
    "\n",
    "        clusters = cluster_class_points(class_points, cid)\n",
    "\n",
    "        if cid == 2 and len(clusters) > 1:\n",
    "            clusters = merge_cable_clusters(clusters)\n",
    "\n",
    "        # Build BallTree once per class for confidence lookup\n",
    "        conf_tree = None\n",
    "        if class_conf is not None and len(clusters) > 0:\n",
    "            conf_tree = BallTree(class_points)\n",
    "\n",
    "        for pts in clusters:\n",
    "            if len(pts) < 3:\n",
    "                continue\n",
    "\n",
    "            # Compute mean confidence for this cluster\n",
    "            box_confidence = 0.0\n",
    "            if conf_tree is not None:\n",
    "                _, indices = conf_tree.query(pts, k=1)\n",
    "                box_confidence = float(class_conf[indices.ravel()].mean())\n",
    "\n",
    "            bbox = pca_oriented_bbox(pts)\n",
    "            boxes.append({\n",
    "                \"center_xyz\": bbox[\"center_xyz\"],\n",
    "                \"dimensions\": bbox[\"dimensions\"],\n",
    "                \"yaw\": bbox[\"yaw\"],\n",
    "                \"class_id\": cid,\n",
    "                \"class_label\": CLASS_LABELS_CSV[cid],\n",
    "                \"num_points\": len(pts),\n",
    "                \"confidence\": box_confidence,\n",
    "            })\n",
    "\n",
    "    # Geometric reclassification (before confidence filter)\n",
    "    boxes = reclassify_by_geometry(boxes)\n",
    "\n",
    "    # Per-class box confidence filter\n",
    "    if use_per_class_conf:\n",
    "        filtered = []\n",
    "        for b in boxes:\n",
    "            thresh = BOX_CONFIDENCE_THRESHOLD_PER_CLASS.get(\n",
    "                b[\"class_id\"], BOX_CONFIDENCE_THRESHOLD_DEFAULT)\n",
    "            if b[\"confidence\"] >= thresh:\n",
    "                filtered.append(b)\n",
    "        boxes = filtered\n",
    "\n",
    "    # Post-processing\n",
    "    boxes = filter_boxes(boxes)\n",
    "    boxes = nms_boxes(boxes)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "print(\"Pipeline functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualization with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_wireframe_box(center, dims, yaw, color, name=\"\"):\n",
    "    \"\"\"Create 3D wireframe box as Plotly Scatter3d traces.\n",
    "    Returns list of traces for the 12 edges of the box.\n",
    "    \"\"\"\n",
    "    cx, cy, cz = center\n",
    "    w, l, h = dims\n",
    "    hw, hl, hh = w / 2, l / 2, h / 2\n",
    "\n",
    "    # 8 corners in local frame\n",
    "    corners_local = np.array([\n",
    "        [-hw, -hl, -hh], [ hw, -hl, -hh], [ hw,  hl, -hh], [-hw,  hl, -hh],\n",
    "        [-hw, -hl,  hh], [ hw, -hl,  hh], [ hw,  hl,  hh], [-hw,  hl,  hh],\n",
    "    ])\n",
    "\n",
    "    # Rotate by yaw around Z axis\n",
    "    cos_y, sin_y = np.cos(yaw), np.sin(yaw)\n",
    "    R = np.array([[cos_y, -sin_y, 0], [sin_y, cos_y, 0], [0, 0, 1]])\n",
    "    corners = (R @ corners_local.T).T + center\n",
    "\n",
    "    # 12 edges\n",
    "    edges = [\n",
    "        [0, 1], [1, 2], [2, 3], [3, 0],  # bottom\n",
    "        [4, 5], [5, 6], [6, 7], [7, 4],  # top\n",
    "        [0, 4], [1, 5], [2, 6], [3, 7],  # vertical\n",
    "    ]\n",
    "\n",
    "    traces = []\n",
    "    for i, (a, b) in enumerate(edges):\n",
    "        traces.append(go.Scatter3d(\n",
    "            x=[corners[a, 0], corners[b, 0]],\n",
    "            y=[corners[a, 1], corners[b, 1]],\n",
    "            z=[corners[a, 2], corners[b, 2]],\n",
    "            mode='lines',\n",
    "            line=dict(color=color, width=4),\n",
    "            name=name if i == 0 else \"\",\n",
    "            showlegend=(i == 0),\n",
    "            legendgroup=name,\n",
    "            hoverinfo='name',\n",
    "        ))\n",
    "    return traces\n",
    "\n",
    "\n",
    "def visualize_frame_3d(xyz_m, predictions, boxes, frame_idx):\n",
    "    \"\"\"Create interactive 3D plotly figure for one frame.\"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Subsample points for display\n",
    "    bg_mask = predictions == 0\n",
    "    obs_mask = ~bg_mask\n",
    "\n",
    "    # Background: heavy subsample\n",
    "    bg_indices = np.where(bg_mask)[0]\n",
    "    if len(bg_indices) > MAX_BG_POINTS:\n",
    "        bg_indices = np.random.choice(bg_indices, MAX_BG_POINTS, replace=False)\n",
    "\n",
    "    # Obstacles: lighter subsample\n",
    "    obs_indices = np.where(obs_mask)[0]\n",
    "    if len(obs_indices) > MAX_OBS_POINTS:\n",
    "        obs_indices = np.random.choice(obs_indices, MAX_OBS_POINTS, replace=False)\n",
    "\n",
    "    # Plot background points\n",
    "    if len(bg_indices) > 0:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=xyz_m[bg_indices, 0],\n",
    "            y=xyz_m[bg_indices, 1],\n",
    "            z=xyz_m[bg_indices, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=POINT_SIZE, color=CLASS_COLORS_PLOTLY[0], opacity=0.15),\n",
    "            name=f'Background ({len(bg_indices):,}pts)',\n",
    "            hoverinfo='name',\n",
    "        ))\n",
    "\n",
    "    # Plot obstacle points by class\n",
    "    for cid in [1, 2, 3, 4]:\n",
    "        class_mask_in_obs = predictions[obs_indices] == cid\n",
    "        cid_indices = obs_indices[class_mask_in_obs]\n",
    "        if len(cid_indices) == 0:\n",
    "            continue\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=xyz_m[cid_indices, 0],\n",
    "            y=xyz_m[cid_indices, 1],\n",
    "            z=xyz_m[cid_indices, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=POINT_SIZE + 1, color=CLASS_COLORS_PLOTLY[cid], opacity=0.8),\n",
    "            name=f'{CLASS_NAMES[cid]} ({len(cid_indices):,}pts)',\n",
    "        ))\n",
    "\n",
    "    # Add bounding boxes as wireframes\n",
    "    box_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "    for box in boxes:\n",
    "        cid = box['class_id']\n",
    "        box_counts[cid] += 1\n",
    "        color = BOX_COLORS_PLOTLY[cid]\n",
    "        label = f\"{CLASS_NAMES[cid]} box #{box_counts[cid]} ({box['num_points']}pts, conf={box['confidence']:.2f})\"\n",
    "        traces = create_3d_wireframe_box(\n",
    "            box['center_xyz'], box['dimensions'], box['yaw'],\n",
    "            color=color, name=label\n",
    "        )\n",
    "        for t in traces:\n",
    "            fig.add_trace(t)\n",
    "\n",
    "    # Layout\n",
    "    box_summary = \", \".join(f\"{CLASS_NAMES[c]}={box_counts[c]}\" for c in [1, 2, 3, 4] if box_counts[c] > 0)\n",
    "    fig.update_layout(\n",
    "        title=f\"Frame {frame_idx} — {len(boxes)} boxes ({box_summary})\",\n",
    "        scene=dict(\n",
    "            xaxis_title='X (m)',\n",
    "            yaxis_title='Y (m)',\n",
    "            zaxis_title='Z (m)',\n",
    "            aspectmode='data',  # preserve real proportions\n",
    "            bgcolor='rgb(20, 20, 30)',\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\", y=0.99,\n",
    "            xanchor=\"left\", x=0.01,\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            font=dict(size=10),\n",
    "        ),\n",
    "        paper_bgcolor='rgb(30, 30, 40)',\n",
    "        font=dict(color='white'),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"Visualization functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = os.path.join(INPUT_DIR, f\"{SINGLE_SCENE}.h5\")\n",
    "print(f\"Loading frame boundaries from {h5_path}...\")\n",
    "t0 = time.time()\n",
    "frames_info = get_frame_boundaries(h5_path)\n",
    "print(f\"{len(frames_info)} frames found ({time.time() - t0:.1f}s)\")\n",
    "\n",
    "# Select frame\n",
    "idx = min(FRAME_INDEX, len(frames_info) - 1)\n",
    "start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n",
    "print(f\"\\nProcessing frame {idx} (points {start}-{end})...\")\n",
    "\n",
    "# Read + inference\n",
    "xyz_m, features = read_frame_for_inference(h5_path, start, end)\n",
    "print(f\"  {len(xyz_m):,} points\")\n",
    "\n",
    "predictions, confidences = predict_frame(model, features, device)\n",
    "del features\n",
    "\n",
    "# Boxes\n",
    "boxes = predictions_to_boxes(xyz_m, predictions, confidences)\n",
    "print(f\"  {len(boxes)} boxes detected\")\n",
    "for cid in [1, 2, 3, 4]:\n",
    "    n = sum(1 for b in boxes if b['class_id'] == cid)\n",
    "    if n > 0:\n",
    "        print(f\"    {CLASS_NAMES[cid]}: {n}\")\n",
    "\n",
    "# Visualize\n",
    "print(\"\\nRendering 3D visualization...\")\n",
    "fig = visualize_frame_3d(xyz_m, predictions, boxes, idx)\n",
    "fig.show()\n",
    "print(\"Done! Rotate/zoom/pan with your mouse.\")\n",
    "\n",
    "del xyz_m, predictions, confidences; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try another frame\n",
    "\n",
    "Change `NEW_FRAME` below and run the cell to visualize a different frame.\n",
    "\n",
    "No need to re-run the frame boundaries or reload the model — just pick a new index.\n",
    "\n",
    "Interesting frames to try: **27, 30, 44, 65, 69, 77** (lots of obstacles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this and run this cell\n",
    "NEW_FRAME = 65  # try different frames: 27, 30, 44, 65, 69, 77\n",
    "\n",
    "idx = min(NEW_FRAME, len(frames_info) - 1)\n",
    "start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n",
    "xyz_m, features = read_frame_for_inference(h5_path, start, end)\n",
    "predictions, confidences = predict_frame(model, features, device)\n",
    "del features\n",
    "boxes = predictions_to_boxes(xyz_m, predictions, confidences)\n",
    "print(f\"Frame {idx}: {len(xyz_m):,} points, {len(boxes)} boxes\")\n",
    "for cid in [1, 2, 3, 4]:\n",
    "    n = sum(1 for b in boxes if b['class_id'] == cid)\n",
    "    if n > 0:\n",
    "        print(f\"  {CLASS_NAMES[cid]}: {n}\")\n",
    "\n",
    "fig = visualize_frame_3d(xyz_m, predictions, boxes, idx)\n",
    "fig.show()\n",
    "\n",
    "del xyz_m, predictions, confidences; gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
