{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 — Visualizations (v7.3)\n",
    "\n",
    "**Notebook Colab** pour générer les screenshots de visualisation (Livrable #4 Airbus).\n",
    "\n",
    "Produit jusqu'à 10 PNGs montrant les nuages de points avec les bounding boxes 3D prédites, colorées par classe.\n",
    "Deux vues par frame : **top-down (XY)** et **side view (XZ)**.\n",
    "\n",
    "**Pipeline :** HDF5 → inference PointNetSegV4 → clustering DBSCAN → PCA bounding boxes → matplotlib 2-panel figure → PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install -q h5py scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# ==========================================================================\n",
    "# PATHS\n",
    "# ==========================================================================\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/airbus_hackathon\"\n",
    "INPUT_DIR = f\"{DRIVE_BASE}/data\"\n",
    "OUTPUT_DIR = f\"{DRIVE_BASE}/outputs/visualizations_v73\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Checkpoint (auto-select best)\n",
    "CKPT_V5 = f\"{DRIVE_BASE}/checkpoints_v5/best_model_v5.pt\"\n",
    "CKPT_V4 = f\"{DRIVE_BASE}/checkpoints_v4/best_model_v4.pt\"\n",
    "CKPT_PATH = CKPT_V5 if os.path.exists(CKPT_V5) else CKPT_V4\n",
    "\n",
    "SINGLE_SCENE = \"scene_8\"  # Scene to visualize\n",
    "NUM_FRAMES = 10           # Number of frames to visualize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Checkpoint: {CKPT_PATH}\")\n",
    "print(f\"Input dir:  {INPUT_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"Device:     {device}\")\n",
    "print(f\"Scene:      {SINGLE_SCENE}\")\n",
    "print(f\"Frames:     {NUM_FRAMES}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU:        {torch.cuda.get_device_name()}\")\n",
    "    print(f\"VRAM:       {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config (v7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "IN_CHANNELS = 5  # x, y, z, reflectivity, norm_distance\n",
    "CHUNK_SIZE = 65536  # points per forward pass\n",
    "\n",
    "CLASS_NAMES = {0: \"Background\", 1: \"Antenna\", 2: \"Cable\", 3: \"Electric pole\", 4: \"Wind turbine\"}\n",
    "\n",
    "# Airbus spec labels\n",
    "CLASS_LABELS_CSV = {1: \"Antenna\", 2: \"Cable\", 3: \"Electric Pole\", 4: \"Wind Turbine\"}\n",
    "\n",
    "# Internal class_id (1-4) -> Airbus class_ID (0-3)\n",
    "CLASS_ID_TO_AIRBUS = {1: 0, 2: 1, 3: 2, 4: 3}\n",
    "\n",
    "# Colors for visualization (RGBA)\n",
    "CLASS_COLORS = {\n",
    "    0: (0.7, 0.7, 0.7, 0.05),    # background — very transparent grey\n",
    "    1: (0.15, 0.09, 0.71, 0.9),   # antenna — blue (from RGB 38,23,180)\n",
    "    2: (0.69, 0.52, 0.18, 0.9),   # cable — gold (from RGB 177,132,47)\n",
    "    3: (0.51, 0.32, 0.38, 0.9),   # electric pole — mauve (from RGB 129,81,97)\n",
    "    4: (0.26, 0.52, 0.04, 0.9),   # wind turbine — green (from RGB 66,132,9)\n",
    "}\n",
    "\n",
    "# Bounding box edge colors (opaque, vivid)\n",
    "BOX_COLORS = {\n",
    "    1: \"#2617B4\",   # antenna — blue\n",
    "    2: \"#B18430\",   # cable — gold\n",
    "    3: \"#815161\",   # electric pole — mauve\n",
    "    4: \"#428409\",   # wind turbine — green\n",
    "}\n",
    "\n",
    "# DBSCAN per-class params\n",
    "DBSCAN_PARAMS = {\n",
    "    1: {\"eps\": 2.0, \"min_samples\": 15},    # Antenna\n",
    "    2: {\"eps\": 5.0, \"min_samples\": 5},     # Cable\n",
    "    3: {\"eps\": 2.0, \"min_samples\": 8},     # Electric pole\n",
    "    4: {\"eps\": 5.0, \"min_samples\": 20},    # Wind turbine\n",
    "}\n",
    "\n",
    "CABLE_MERGE_ANGLE_DEG = 15.0\n",
    "CABLE_MERGE_GAP_M = 10.0\n",
    "\n",
    "# === v7.3: Per-class confidence thresholds ===\n",
    "CONFIDENCE_THRESHOLD_PER_CLASS = {\n",
    "    1: 0.40,  # antenna\n",
    "    2: 0.27,  # cable\n",
    "    3: 0.25,  # electric_pole\n",
    "    4: 0.30,  # wind_turbine\n",
    "}\n",
    "CONFIDENCE_THRESHOLD_DEFAULT = 0.3\n",
    "\n",
    "BOX_CONFIDENCE_THRESHOLD_PER_CLASS = {\n",
    "    1: 0.70,  # antenna\n",
    "    2: 0.55,  # cable\n",
    "    3: 0.45,  # electric_pole\n",
    "    4: 0.60,  # wind_turbine\n",
    "}\n",
    "BOX_CONFIDENCE_THRESHOLD_DEFAULT = 0.6\n",
    "\n",
    "MIN_POINTS_PER_BOX = {1: 15, 2: 3, 3: 5, 4: 15}\n",
    "MAX_DIM_PER_CLASS = {1: 200.0, 2: 400.0, 3: 100.0, 4: 250.0}\n",
    "NMS_IOU_THRESHOLD = 0.3\n",
    "\n",
    "print(\"Config v7.3 loaded.\")\n",
    "print(f\"Per-class point conf:  {CONFIDENCE_THRESHOLD_PER_CLASS}\")\n",
    "print(f\"Per-class box conf:    {BOX_CONFIDENCE_THRESHOLD_PER_CLASS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMLP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bn=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, 1, bias=not bn)\n",
    "        self.bn = nn.BatchNorm1d(out_ch) if bn else None\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class PointNetSegV4(nn.Module):\n",
    "    \"\"\"PointNet v4 segmentation — multi-scale skips, ~1.88M params.\"\"\"\n",
    "    def __init__(self, in_channels=5, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.enc1 = SharedMLP(in_channels, 64)\n",
    "        self.enc2 = SharedMLP(64, 128)\n",
    "        self.enc3 = SharedMLP(128, 256)\n",
    "        self.enc4 = SharedMLP(256, 512)\n",
    "        self.enc5 = SharedMLP(512, 1024)\n",
    "        self.seg1 = SharedMLP(64 + 128 + 256 + 512 + 1024, 512)\n",
    "        self.seg2 = SharedMLP(512, 256)\n",
    "        self.seg3 = SharedMLP(256, 128)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.head = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.shape\n",
    "        x = x.transpose(1, 2)\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "        g = e5.max(dim=2, keepdim=True)[0].expand(-1, -1, N)\n",
    "        seg = torch.cat([e1, e2, e3, e4, g], dim=1)\n",
    "        seg = self.seg1(seg)\n",
    "        seg = self.dropout1(seg)\n",
    "        seg = self.seg2(seg)\n",
    "        seg = self.dropout2(seg)\n",
    "        seg = self.seg3(seg)\n",
    "        seg = self.head(seg)\n",
    "        return seg.transpose(1, 2)\n",
    "\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading {CKPT_PATH}...\")\n",
    "model = PointNetSegV4(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES).to(device)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"PointNetSegV4: {n_params:,} params on {device}\")\n",
    "if \"val_obstacle_miou\" in ckpt:\n",
    "    print(f\"Epoch {ckpt.get('epoch', '?')}, val obstacle mIoU={ckpt['val_obstacle_miou']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 Reader + Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HDF5 READER ===\n",
    "\n",
    "def get_frame_boundaries(h5_path, dataset_name=\"lidar_points\", chunk_size=2_000_000):\n",
    "    change_indices = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        n = ds.shape[0]\n",
    "        prev_last_pose = None\n",
    "        for offset in range(0, n, chunk_size):\n",
    "            end = min(offset + chunk_size, n)\n",
    "            chunk = ds[offset:end]\n",
    "            ex, ey, ez, eyaw = chunk[\"ego_x\"], chunk[\"ego_y\"], chunk[\"ego_z\"], chunk[\"ego_yaw\"]\n",
    "            if prev_last_pose is not None:\n",
    "                cur_first = (int(ex[0]), int(ey[0]), int(ez[0]), int(eyaw[0]))\n",
    "                if cur_first != prev_last_pose:\n",
    "                    change_indices.append(offset)\n",
    "            changes = np.where(\n",
    "                (np.diff(ex) != 0) | (np.diff(ey) != 0) |\n",
    "                (np.diff(ez) != 0) | (np.diff(eyaw) != 0)\n",
    "            )[0] + 1\n",
    "            for c in changes:\n",
    "                change_indices.append(offset + int(c))\n",
    "            prev_last_pose = (int(ex[-1]), int(ey[-1]), int(ez[-1]), int(eyaw[-1]))\n",
    "            del chunk, ex, ey, ez, eyaw; gc.collect()\n",
    "    starts = [0] + change_indices\n",
    "    ends = change_indices + [n]\n",
    "    frames = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        for s, e in zip(starts, ends):\n",
    "            row = ds[s]\n",
    "            frames.append((s, e, int(row[\"ego_x\"]), int(row[\"ego_y\"]),\n",
    "                           int(row[\"ego_z\"]), int(row[\"ego_yaw\"])))\n",
    "    return frames\n",
    "\n",
    "\n",
    "def read_frame_for_inference(h5_path, start, end, dataset_name=\"lidar_points\"):\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        chunk = f[dataset_name][start:end]\n",
    "    valid = chunk[chunk[\"distance_cm\"] > 0]\n",
    "    del chunk\n",
    "    dist_m = valid[\"distance_cm\"].astype(np.float64) / 100.0\n",
    "    az_rad = np.radians(valid[\"azimuth_raw\"].astype(np.float64) / 100.0)\n",
    "    el_rad = np.radians(valid[\"elevation_raw\"].astype(np.float64) / 100.0)\n",
    "    cos_el = np.cos(el_rad)\n",
    "    x = dist_m * cos_el * np.cos(az_rad)\n",
    "    y = -dist_m * cos_el * np.sin(az_rad)\n",
    "    z = dist_m * np.sin(el_rad)\n",
    "    xyz = np.column_stack((x, y, z)).astype(np.float32)\n",
    "    refl_norm = (valid[\"reflectivity\"].astype(np.float32) / 255.0).reshape(-1, 1)\n",
    "    dist_norm = (dist_m.astype(np.float32) / 300.0).reshape(-1, 1)\n",
    "    features = np.concatenate([xyz, refl_norm, dist_norm], axis=1)\n",
    "    del valid, dist_m, az_rad, el_rad, cos_el, x, y, z\n",
    "    return xyz, features\n",
    "\n",
    "\n",
    "# === INFERENCE (v7.3 — per-class confidence thresholds) ===\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_frame(model, features_np, device, chunk_size=CHUNK_SIZE):\n",
    "    \"\"\"Standard inference with per-class confidence thresholds.\"\"\"\n",
    "    n = len(features_np)\n",
    "    predictions = np.zeros(n, dtype=np.int64)\n",
    "    confidences = np.zeros(n, dtype=np.float32)\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk = features_np[start:end]\n",
    "        pad_to = max(len(chunk), 128)\n",
    "        if len(chunk) < pad_to:\n",
    "            padded = np.zeros((pad_to, chunk.shape[1]), dtype=np.float32)\n",
    "            padded[:len(chunk)] = chunk\n",
    "        else:\n",
    "            padded = chunk\n",
    "        tensor = torch.from_numpy(padded).unsqueeze(0).to(device)\n",
    "        logits = model(tensor)\n",
    "        probs = F.softmax(logits[0, :len(chunk)], dim=-1)\n",
    "        conf, preds = probs.max(dim=-1)\n",
    "        preds, conf = preds.cpu().numpy(), conf.cpu().numpy()\n",
    "        # Per-class confidence threshold\n",
    "        for cid in range(1, 5):\n",
    "            thresh = CONFIDENCE_THRESHOLD_PER_CLASS.get(cid, CONFIDENCE_THRESHOLD_DEFAULT)\n",
    "            low_conf = (preds == cid) & (conf < thresh)\n",
    "            preds[low_conf] = 0\n",
    "        predictions[start:end] = preds\n",
    "        confidences[start:end] = conf\n",
    "        del tensor, logits, probs, preds, conf\n",
    "    return predictions, confidences\n",
    "\n",
    "\n",
    "print(\"HDF5 reader + inference functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering + Post-processing (v7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_oriented_bbox(points_m):\n",
    "    center_xyz = points_m.mean(axis=0)\n",
    "    centered = points_m - center_xyz\n",
    "    cov = np.cov(centered.T)\n",
    "    if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "        mins, maxs = points_m.min(axis=0), points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        mins, maxs = points_m.min(axis=0), points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "    projected = centered @ eigenvectors\n",
    "    mins, maxs = projected.min(axis=0), projected.max(axis=0)\n",
    "    dimensions = maxs - mins\n",
    "    box_center_pca = (mins + maxs) / 2.0\n",
    "    center_xyz = center_xyz + eigenvectors @ box_center_pca\n",
    "    yaw = np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0])\n",
    "    return {\"center_xyz\": center_xyz, \"dimensions\": dimensions, \"yaw\": float(yaw)}\n",
    "\n",
    "\n",
    "def cluster_class_points(points_m, class_id, max_points=10000):\n",
    "    params = DBSCAN_PARAMS[class_id]\n",
    "    eps, min_samples = params[\"eps\"], params[\"min_samples\"]\n",
    "    if len(points_m) < min_samples:\n",
    "        return []\n",
    "    full_points = points_m\n",
    "    if len(points_m) > max_points:\n",
    "        idx = np.random.choice(len(points_m), max_points, replace=False)\n",
    "        points_m = points_m[idx]\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"ball_tree\").fit_predict(points_m)\n",
    "    if len(full_points) > max_points:\n",
    "        sampled_mask = labels >= 0\n",
    "        if sampled_mask.sum() == 0:\n",
    "            return []\n",
    "        tree = BallTree(points_m[sampled_mask])\n",
    "        _, indices = tree.query(full_points, k=1)\n",
    "        full_labels = labels[sampled_mask][indices.ravel()]\n",
    "        dists = np.linalg.norm(full_points - points_m[sampled_mask][indices.ravel()], axis=1)\n",
    "        full_labels[dists > eps * 2] = -1\n",
    "        labels = full_labels\n",
    "        points_m = full_points\n",
    "    clusters = []\n",
    "    for lbl in sorted(set(labels) - {-1}):\n",
    "        clusters.append(points_m[labels == lbl])\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def merge_cable_clusters(clusters):\n",
    "    if len(clusters) <= 1:\n",
    "        return clusters\n",
    "    angle_thresh = np.radians(CABLE_MERGE_ANGLE_DEG)\n",
    "    gap_thresh = CABLE_MERGE_GAP_M\n",
    "    infos = []\n",
    "    for pts in clusters:\n",
    "        if len(pts) < 4:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        centered = pts - pts.mean(axis=0)\n",
    "        cov = np.cov(centered.T)\n",
    "        if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        try:\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "        except np.linalg.LinAlgError:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        axis1 = eigvecs[:, eigvals.argsort()[::-1][0]]\n",
    "        if axis1[0] < 0: axis1 = -axis1\n",
    "        infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": axis1})\n",
    "    merged_flags = [False] * len(infos)\n",
    "    result = []\n",
    "    for i in range(len(infos)):\n",
    "        if merged_flags[i]: continue\n",
    "        current = infos[i][\"points\"]\n",
    "        if infos[i][\"axis1\"] is not None:\n",
    "            for j in range(i + 1, len(infos)):\n",
    "                if merged_flags[j] or infos[j][\"axis1\"] is None: continue\n",
    "                dot = min(abs(np.dot(infos[i][\"axis1\"], infos[j][\"axis1\"])), 1.0)\n",
    "                if np.arccos(dot) > angle_thresh: continue\n",
    "                cdist = np.linalg.norm(infos[i][\"center\"] - infos[j][\"center\"])\n",
    "                ext_i = np.abs((infos[i][\"points\"] - infos[i][\"center\"]) @ infos[i][\"axis1\"]).max()\n",
    "                ext_j = np.abs((infos[j][\"points\"] - infos[j][\"center\"]) @ infos[j][\"axis1\"]).max()\n",
    "                if cdist - ext_i - ext_j <= gap_thresh:\n",
    "                    current = np.vstack([current, infos[j][\"points\"]])\n",
    "                    merged_flags[j] = True\n",
    "        result.append(current)\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_boxes(boxes):\n",
    "    return [b for b in boxes\n",
    "            if b[\"num_points\"] >= MIN_POINTS_PER_BOX.get(b[\"class_id\"], 3)\n",
    "            and max(b[\"dimensions\"]) <= MAX_DIM_PER_CLASS.get(b[\"class_id\"], 500.0)]\n",
    "\n",
    "\n",
    "def _box_iou_3d(a, b):\n",
    "    ca, da, cb, db = a[\"center_xyz\"], a[\"dimensions\"], b[\"center_xyz\"], b[\"dimensions\"]\n",
    "    ha, hb = da / 2.0, db / 2.0\n",
    "    overlap = np.maximum(0, np.minimum(ca + ha, cb + hb) - np.maximum(ca - ha, cb - hb))\n",
    "    inter = overlap[0] * overlap[1] * overlap[2]\n",
    "    union = da[0]*da[1]*da[2] + db[0]*db[1]*db[2] - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, iou_threshold=NMS_IOU_THRESHOLD):\n",
    "    if len(boxes) <= 1: return boxes\n",
    "    by_class = {}\n",
    "    for b in boxes: by_class.setdefault(b[\"class_id\"], []).append(b)\n",
    "    result = []\n",
    "    for cid, cb in by_class.items():\n",
    "        cb.sort(key=lambda b: b[\"num_points\"], reverse=True)\n",
    "        suppressed = [False] * len(cb)\n",
    "        for i in range(len(cb)):\n",
    "            if suppressed[i]: continue\n",
    "            result.append(cb[i])\n",
    "            for j in range(i+1, len(cb)):\n",
    "                if not suppressed[j] and _box_iou_3d(cb[i], cb[j]) > iou_threshold:\n",
    "                    suppressed[j] = True\n",
    "    return result\n",
    "\n",
    "\n",
    "def reclassify_by_geometry(boxes):\n",
    "    \"\"\"Reclassify boxes based on geometric properties.\n",
    "    Fixes common model confusions:\n",
    "    - Antenna classified but shape is elongated + flat -> likely Cable\n",
    "    - Antenna classified but very large + many points -> likely Wind Turbine\n",
    "    \"\"\"\n",
    "    for box in boxes:\n",
    "        if box[\"class_id\"] != 1:  # only reclassify from antenna\n",
    "            continue\n",
    "        dims = box[\"dimensions\"]\n",
    "        sorted_dims = sorted(dims, reverse=True)\n",
    "        longest, middle, shortest = sorted_dims\n",
    "        # Elongated + flat -> Cable\n",
    "        if middle > 0 and longest / middle > 5.0 and shortest < 1.0:\n",
    "            box[\"class_id\"] = 2\n",
    "            box[\"class_label\"] = CLASS_LABELS_CSV[2]\n",
    "        # Very large + many points -> Wind Turbine\n",
    "        elif longest > 15.0 and box[\"num_points\"] > 200:\n",
    "            box[\"class_id\"] = 4\n",
    "            box[\"class_label\"] = CLASS_LABELS_CSV[4]\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def predictions_to_boxes(xyz_m, predictions, confidences=None):\n",
    "    \"\"\"v7.3: cluster -> PCA bbox -> geometric reclassification -> per-class confidence filter -> size filter -> NMS.\"\"\"\n",
    "    boxes = []\n",
    "    for cid in range(1, 5):\n",
    "        mask = predictions == cid\n",
    "        if mask.sum() == 0: continue\n",
    "        class_points = xyz_m[mask]\n",
    "        class_conf = confidences[mask] if confidences is not None else None\n",
    "        clusters = cluster_class_points(class_points, cid)\n",
    "        if cid == 2 and len(clusters) > 1:\n",
    "            clusters = merge_cable_clusters(clusters)\n",
    "        conf_tree = None\n",
    "        if class_conf is not None and len(clusters) > 0:\n",
    "            conf_tree = BallTree(class_points)\n",
    "        for pts in clusters:\n",
    "            if len(pts) < 3: continue\n",
    "            box_confidence = 0.0\n",
    "            if conf_tree is not None:\n",
    "                _, indices = conf_tree.query(pts, k=1)\n",
    "                box_confidence = float(class_conf[indices.ravel()].mean())\n",
    "            bbox = pca_oriented_bbox(pts)\n",
    "            boxes.append({\n",
    "                \"center_xyz\": bbox[\"center_xyz\"], \"dimensions\": bbox[\"dimensions\"],\n",
    "                \"yaw\": bbox[\"yaw\"], \"class_id\": cid, \"class_label\": CLASS_LABELS_CSV[cid],\n",
    "                \"num_points\": len(pts), \"confidence\": box_confidence,\n",
    "            })\n",
    "    # Geometric reclassification (before confidence filter)\n",
    "    boxes = reclassify_by_geometry(boxes)\n",
    "    # Per-class box confidence filter\n",
    "    filtered = []\n",
    "    for b in boxes:\n",
    "        thresh = BOX_CONFIDENCE_THRESHOLD_PER_CLASS.get(\n",
    "            b[\"class_id\"], BOX_CONFIDENCE_THRESHOLD_DEFAULT)\n",
    "        if b[\"confidence\"] >= thresh:\n",
    "            filtered.append(b)\n",
    "    boxes = filtered\n",
    "    boxes = filter_boxes(boxes)\n",
    "    boxes = nms_boxes(boxes)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "print(\"Clustering + post-processing v7.3 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rotated_box_2d(ax, cx, cy, w, h, yaw, color, linewidth=2):\n",
    "    \"\"\"Draw a rotated rectangle on a 2D matplotlib axes.\"\"\"\n",
    "    cos_y, sin_y = np.cos(yaw), np.sin(yaw)\n",
    "    # 4 corners of the box before rotation\n",
    "    corners = np.array([\n",
    "        [-w/2, -h/2],\n",
    "        [+w/2, -h/2],\n",
    "        [+w/2, +h/2],\n",
    "        [-w/2, +h/2],\n",
    "        [-w/2, -h/2],  # close the box\n",
    "    ])\n",
    "    # Rotate\n",
    "    rot = np.array([[cos_y, -sin_y], [sin_y, cos_y]])\n",
    "    rotated = corners @ rot.T\n",
    "    rotated[:, 0] += cx\n",
    "    rotated[:, 1] += cy\n",
    "    ax.plot(rotated[:, 0], rotated[:, 1], color=color, linewidth=linewidth, solid_capstyle='round')\n",
    "\n",
    "\n",
    "def render_frame(xyz_m, predictions, boxes, frame_idx, ego_info, output_path,\n",
    "                 max_display_points=100000):\n",
    "    \"\"\"Render a frame with two views: top-down (XY) and side (XZ).\"\"\"\n",
    "\n",
    "    # Subsample points for display\n",
    "    if len(xyz_m) > max_display_points:\n",
    "        idx = np.random.choice(len(xyz_m), max_display_points, replace=False)\n",
    "        xyz_disp = xyz_m[idx]\n",
    "        pred_disp = predictions[idx]\n",
    "    else:\n",
    "        xyz_disp = xyz_m\n",
    "        pred_disp = predictions\n",
    "\n",
    "    # Assign colors to points\n",
    "    colors = np.array([CLASS_COLORS[p] for p in pred_disp])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "    ego_x, ego_y, ego_z, ego_yaw = ego_info\n",
    "\n",
    "    # --- Top-down view (XY) ---\n",
    "    ax = axes[0]\n",
    "    # Background points first (below), then obstacle points on top\n",
    "    bg_mask = pred_disp == 0\n",
    "    obs_mask = ~bg_mask\n",
    "\n",
    "    ax.scatter(xyz_disp[bg_mask, 0], xyz_disp[bg_mask, 1],\n",
    "               c=colors[bg_mask], s=0.1, rasterized=True)\n",
    "    ax.scatter(xyz_disp[obs_mask, 0], xyz_disp[obs_mask, 1],\n",
    "               c=colors[obs_mask], s=1.5, rasterized=True)\n",
    "\n",
    "    # Draw bounding boxes (top-down: use X, Y, width, length, yaw)\n",
    "    for box in boxes:\n",
    "        c = box[\"center_xyz\"]\n",
    "        d = box[\"dimensions\"]\n",
    "        draw_rotated_box_2d(ax, c[0], c[1], d[0], d[1], box[\"yaw\"],\n",
    "                           color=BOX_COLORS[box[\"class_id\"]], linewidth=2.5)\n",
    "\n",
    "    ax.set_xlabel(\"X (m)\", fontsize=11)\n",
    "    ax.set_ylabel(\"Y (m)\", fontsize=11)\n",
    "    ax.set_title(\"Top-down view (XY)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # --- Side view (XZ) ---\n",
    "    ax = axes[1]\n",
    "    ax.scatter(xyz_disp[bg_mask, 0], xyz_disp[bg_mask, 2],\n",
    "               c=colors[bg_mask], s=0.1, rasterized=True)\n",
    "    ax.scatter(xyz_disp[obs_mask, 0], xyz_disp[obs_mask, 2],\n",
    "               c=colors[obs_mask], s=1.5, rasterized=True)\n",
    "\n",
    "    # Draw bounding boxes (side: use X, Z, width, height, no rotation)\n",
    "    for box in boxes:\n",
    "        c = box[\"center_xyz\"]\n",
    "        d = box[\"dimensions\"]\n",
    "        # Side view: axis-aligned rectangle (X, Z)\n",
    "        rect = patches.Rectangle(\n",
    "            (c[0] - d[0]/2, c[2] - d[2]/2), d[0], d[2],\n",
    "            linewidth=2.5, edgecolor=BOX_COLORS[box[\"class_id\"]],\n",
    "            facecolor=\"none\", linestyle=\"-\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.set_xlabel(\"X (m)\", fontsize=11)\n",
    "    ax.set_ylabel(\"Z (m)\", fontsize=11)\n",
    "    ax.set_title(\"Side view (XZ)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Legend\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color=BOX_COLORS[1], linewidth=3, label=f\"Antenna ({sum(1 for b in boxes if b['class_id']==1)})\"),\n",
    "        Line2D([0], [0], color=BOX_COLORS[2], linewidth=3, label=f\"Cable ({sum(1 for b in boxes if b['class_id']==2)})\"),\n",
    "        Line2D([0], [0], color=BOX_COLORS[3], linewidth=3, label=f\"Electric pole ({sum(1 for b in boxes if b['class_id']==3)})\"),\n",
    "        Line2D([0], [0], color=BOX_COLORS[4], linewidth=3, label=f\"Wind turbine ({sum(1 for b in boxes if b['class_id']==4)})\"),\n",
    "    ]\n",
    "    fig.legend(handles=legend_elements, loc=\"lower center\", ncol=4, fontsize=11,\n",
    "               frameon=True, fancybox=True, shadow=True)\n",
    "\n",
    "    # Title\n",
    "    n_obs = sum(1 for p in predictions if p > 0)\n",
    "    fig.suptitle(\n",
    "        f\"Frame {frame_idx} — {len(boxes)} detections — \"\n",
    "        f\"{n_obs:,} obstacle pts / {len(predictions):,} total — \"\n",
    "        f\"PointNetSegV4 (v7.3)\",\n",
    "        fontsize=14, fontweight=\"bold\", y=0.98\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "    plt.close(fig)\n",
    "    print(f\"  Saved: {output_path}\", flush=True)\n",
    "\n",
    "\n",
    "def select_diverse_frames(all_frame_results, num_frames=10):\n",
    "    \"\"\"Select frames that showcase different class combinations and box counts.\"\"\"\n",
    "    if len(all_frame_results) <= num_frames:\n",
    "        return all_frame_results\n",
    "\n",
    "    # Sort by number of distinct classes detected (descending), then by box count\n",
    "    scored = []\n",
    "    for fr in all_frame_results:\n",
    "        classes_present = set(b[\"class_id\"] for b in fr[\"boxes\"])\n",
    "        scored.append((len(classes_present), len(fr[\"boxes\"]), fr))\n",
    "\n",
    "    scored.sort(key=lambda x: (x[0], x[1]), reverse=True)\n",
    "\n",
    "    selected = []\n",
    "    seen_class_combos = set()\n",
    "\n",
    "    # First pass: pick frames with unique class combinations\n",
    "    for n_cls, n_box, fr in scored:\n",
    "        if len(selected) >= num_frames:\n",
    "            break\n",
    "        combo = frozenset(b[\"class_id\"] for b in fr[\"boxes\"])\n",
    "        if combo not in seen_class_combos:\n",
    "            selected.append(fr)\n",
    "            seen_class_combos.add(combo)\n",
    "\n",
    "    # Second pass: fill remaining slots with highest box count frames\n",
    "    if len(selected) < num_frames:\n",
    "        selected_indices = set(fr[\"frame_idx\"] for fr in selected)\n",
    "        for n_cls, n_box, fr in scored:\n",
    "            if len(selected) >= num_frames:\n",
    "                break\n",
    "            if fr[\"frame_idx\"] not in selected_indices:\n",
    "                selected.append(fr)\n",
    "                selected_indices.add(fr[\"frame_idx\"])\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAIN: Run inference on all frames, select best, render PNGs ===\n",
    "\n",
    "h5_path = os.path.join(INPUT_DIR, f\"{SINGLE_SCENE}.h5\")\n",
    "assert os.path.exists(h5_path), f\"File not found: {h5_path}\"\n",
    "scene_name = SINGLE_SCENE\n",
    "\n",
    "print(f\"Reading frame boundaries from {h5_path}...\")\n",
    "t0 = time.time()\n",
    "frames_info = get_frame_boundaries(h5_path)\n",
    "n_frames = len(frames_info)\n",
    "print(f\"Found {n_frames} frames ({time.time()-t0:.1f}s)\")\n",
    "\n",
    "# Run inference on ALL frames to find the best ones\n",
    "print(f\"\\nRunning inference on all {n_frames} frames to select best {NUM_FRAMES}...\")\n",
    "all_results = []\n",
    "t0 = time.time()\n",
    "\n",
    "for idx in range(n_frames):\n",
    "    start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n",
    "    xyz_m, features = read_frame_for_inference(h5_path, start, end)\n",
    "    if len(xyz_m) == 0:\n",
    "        continue\n",
    "\n",
    "    predictions, confidences = predict_frame(model, features, device)\n",
    "    del features\n",
    "\n",
    "    boxes = predictions_to_boxes(xyz_m, predictions, confidences)\n",
    "\n",
    "    if boxes:  # Only consider frames with detections\n",
    "        all_results.append({\n",
    "            \"frame_idx\": idx,\n",
    "            \"xyz_m\": xyz_m,\n",
    "            \"predictions\": predictions,\n",
    "            \"boxes\": boxes,\n",
    "            \"ego_info\": (ego_x, ego_y, ego_z, ego_yaw),\n",
    "        })\n",
    "    else:\n",
    "        del xyz_m, predictions\n",
    "        gc.collect()\n",
    "\n",
    "    del confidences\n",
    "\n",
    "    if (idx + 1) % 20 == 0:\n",
    "        print(f\"  {idx+1}/{n_frames} frames processed, {len(all_results)} with detections\", flush=True)\n",
    "\n",
    "elapsed_inf = time.time() - t0\n",
    "print(f\"\\nInference done: {len(all_results)} frames with detections ({elapsed_inf:.0f}s)\")\n",
    "\n",
    "# Select diverse frames\n",
    "selected = select_diverse_frames(all_results, NUM_FRAMES)\n",
    "print(f\"Selected {len(selected)} frames for visualization\")\n",
    "\n",
    "# Free unselected frames\n",
    "selected_indices = set(fr[\"frame_idx\"] for fr in selected)\n",
    "for fr in all_results:\n",
    "    if fr[\"frame_idx\"] not in selected_indices:\n",
    "        del fr[\"xyz_m\"], fr[\"predictions\"], fr[\"boxes\"]\n",
    "del all_results\n",
    "gc.collect()\n",
    "\n",
    "# Render selected frames\n",
    "print(f\"\\nRendering visualizations...\")\n",
    "t_render = time.time()\n",
    "\n",
    "for i, fr in enumerate(selected):\n",
    "    filename = f\"{scene_name}_frame{fr['frame_idx']:03d}.png\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "    classes_in_frame = sorted(set(b[\"class_id\"] for b in fr[\"boxes\"]))\n",
    "    class_names = [CLASS_NAMES[c] for c in classes_in_frame]\n",
    "    print(f\"\\n  [{i+1}/{len(selected)}] Frame {fr['frame_idx']}: \"\n",
    "          f\"{len(fr['boxes'])} boxes ({', '.join(class_names)})\", flush=True)\n",
    "\n",
    "    render_frame(\n",
    "        fr[\"xyz_m\"], fr[\"predictions\"], fr[\"boxes\"],\n",
    "        fr[\"frame_idx\"], fr[\"ego_info\"], output_path\n",
    "    )\n",
    "\n",
    "    del fr[\"xyz_m\"], fr[\"predictions\"]\n",
    "    gc.collect()\n",
    "\n",
    "elapsed_render = time.time() - t_render\n",
    "elapsed_total = time.time() - t0 + (t0 - t0)  # total from inference start\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DONE! {len(selected)} visualizations saved to {OUTPUT_DIR}/\")\n",
    "print(f\"Inference: {elapsed_inf:.0f}s, Rendering: {elapsed_render:.0f}s\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# List generated files\n",
    "print(f\"\\nGenerated files:\")\n",
    "for f in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    if f.endswith(\".png\"):\n",
    "        fpath = os.path.join(OUTPUT_DIR, f)\n",
    "        size_mb = os.path.getsize(fpath) / 1e6\n",
    "        print(f\"  {f} ({size_mb:.1f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}