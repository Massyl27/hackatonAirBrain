{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 — Inference Pipeline\n",
    "\n",
    "**Story 3** — Full inference: HDF5 → PointNetSegV4 → DBSCAN → Bounding Boxes → CSV\n",
    "\n",
    "Run on Colab T4/A100. All code inline (no `src/` dependency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install -q h5py scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/airbus_hackathon\"\n",
    "DATA_DIR = f\"{DRIVE_BASE}/data\"\n",
    "CKPT_DIR = f\"{DRIVE_BASE}/checkpoints_v4\"\n",
    "OUTPUT_DIR = f\"{DRIVE_BASE}/outputs/pred_v4\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "IN_CHANNELS = 5  # x, y, z, reflectivity, norm_distance\n",
    "\n",
    "CLASS_NAMES = {0: \"background\", 1: \"antenna\", 2: \"cable\", 3: \"electric_pole\", 4: \"wind_turbine\"}\n",
    "CLASS_LABELS_CSV = {1: \"Antenna\", 2: \"Cable\", 3: \"Electric pole\", 4: \"Wind turbine\"}\n",
    "\n",
    "DBSCAN_PARAMS = {\n",
    "    1: {\"eps\": 2.0, \"min_samples\": 10},\n",
    "    2: {\"eps\": 5.0, \"min_samples\": 5},\n",
    "    3: {\"eps\": 2.0, \"min_samples\": 10},\n",
    "    4: {\"eps\": 5.0, \"min_samples\": 15},\n",
    "}\n",
    "\n",
    "CABLE_MERGE_ANGLE_DEG = 15.0\n",
    "CABLE_MERGE_GAP_M = 10.0\n",
    "\n",
    "CHUNK_SIZE = 65536  # points per forward pass\n",
    "\n",
    "# CSV header — Airbus deliverable format\n",
    "CSV_HEADER = (\"ego_x,ego_y,ego_z,ego_yaw,\"\n",
    "              \"bbox_center_x,bbox_center_y,bbox_center_z,\"\n",
    "              \"bbox_width,bbox_length,bbox_height,\"\n",
    "              \"bbox_yaw,\"\n",
    "              \"class_ID,class_label\\n\")\n",
    "\n",
    "print(\"Config loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (PointNetSegV4 — inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMLP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bn=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, 1, bias=not bn)\n",
    "        self.bn = nn.BatchNorm1d(out_ch) if bn else None\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class PointNetSegV4(nn.Module):\n",
    "    \"\"\"PointNet v4 segmentation — multi-scale skips, ~1.88M params.\"\"\"\n",
    "    def __init__(self, in_channels=5, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.enc1 = SharedMLP(in_channels, 64)\n",
    "        self.enc2 = SharedMLP(64, 128)\n",
    "        self.enc3 = SharedMLP(128, 256)\n",
    "        self.enc4 = SharedMLP(256, 512)\n",
    "        self.enc5 = SharedMLP(512, 1024)\n",
    "        self.seg1 = SharedMLP(64 + 128 + 256 + 512 + 1024, 512)\n",
    "        self.seg2 = SharedMLP(512, 256)\n",
    "        self.seg3 = SharedMLP(256, 128)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.head = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.shape\n",
    "        x = x.transpose(1, 2)\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "        g = e5.max(dim=2, keepdim=True)[0].expand(-1, -1, N)\n",
    "        seg = torch.cat([e1, e2, e3, e4, g], dim=1)\n",
    "        seg = self.seg1(seg)\n",
    "        seg = self.dropout1(seg)\n",
    "        seg = self.seg2(seg)\n",
    "        seg = self.dropout2(seg)\n",
    "        seg = self.seg3(seg)\n",
    "        seg = self.head(seg)\n",
    "        return seg.transpose(1, 2)\n",
    "\n",
    "\n",
    "# Load model\n",
    "ckpt_path = os.path.join(CKPT_DIR, \"best_model_v4.pt\")\n",
    "print(f\"Loading {ckpt_path}...\")\n",
    "\n",
    "model = PointNetSegV4(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES).to(device)\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"PointNetSegV4: {n_params:,} params on {device}\")\n",
    "if \"val_obstacle_miou\" in ckpt:\n",
    "    print(f\"Epoch {ckpt.get('epoch', '?')}, val obstacle mIoU={ckpt['val_obstacle_miou']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 Reader + Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_boundaries(h5_path, dataset_name=\"lidar_points\", chunk_size=2_000_000):\n",
    "    \"\"\"Find frame boundaries by reading in chunks.\"\"\"\n",
    "    change_indices = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        n = ds.shape[0]\n",
    "        prev_last_pose = None\n",
    "        for offset in range(0, n, chunk_size):\n",
    "            end = min(offset + chunk_size, n)\n",
    "            chunk = ds[offset:end]\n",
    "            ex = chunk[\"ego_x\"]\n",
    "            ey = chunk[\"ego_y\"]\n",
    "            ez = chunk[\"ego_z\"]\n",
    "            eyaw = chunk[\"ego_yaw\"]\n",
    "            if prev_last_pose is not None:\n",
    "                cur_first = (int(ex[0]), int(ey[0]), int(ez[0]), int(eyaw[0]))\n",
    "                if cur_first != prev_last_pose:\n",
    "                    change_indices.append(offset)\n",
    "            changes = np.where(\n",
    "                (np.diff(ex) != 0) | (np.diff(ey) != 0) |\n",
    "                (np.diff(ez) != 0) | (np.diff(eyaw) != 0)\n",
    "            )[0] + 1\n",
    "            for c in changes:\n",
    "                change_indices.append(offset + int(c))\n",
    "            prev_last_pose = (int(ex[-1]), int(ey[-1]), int(ez[-1]), int(eyaw[-1]))\n",
    "            del chunk, ex, ey, ez, eyaw\n",
    "            gc.collect()\n",
    "    starts = [0] + change_indices\n",
    "    ends = change_indices + [n]\n",
    "    frames = []\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ds = f[dataset_name]\n",
    "        for s, e in zip(starts, ends):\n",
    "            row = ds[s]\n",
    "            frames.append((s, e, int(row[\"ego_x\"]), int(row[\"ego_y\"]),\n",
    "                           int(row[\"ego_z\"]), int(row[\"ego_yaw\"])))\n",
    "    return frames\n",
    "\n",
    "\n",
    "def read_frame_for_inference(h5_path, start, end, dataset_name=\"lidar_points\"):\n",
    "    \"\"\"Read a single frame and compute features for inference.\n",
    "    Returns: xyz_m (N,3), features (N,5)\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        chunk = f[dataset_name][start:end]\n",
    "    valid = chunk[chunk[\"distance_cm\"] > 0]\n",
    "    del chunk\n",
    "    dist_m = valid[\"distance_cm\"].astype(np.float64) / 100.0\n",
    "    az_rad = np.radians(valid[\"azimuth_raw\"].astype(np.float64) / 100.0)\n",
    "    el_rad = np.radians(valid[\"elevation_raw\"].astype(np.float64) / 100.0)\n",
    "    cos_el = np.cos(el_rad)\n",
    "    x = dist_m * cos_el * np.cos(az_rad)\n",
    "    y = -dist_m * cos_el * np.sin(az_rad)\n",
    "    z = dist_m * np.sin(el_rad)\n",
    "    xyz = np.column_stack((x, y, z)).astype(np.float32)\n",
    "    refl_norm = (valid[\"reflectivity\"].astype(np.float32) / 255.0).reshape(-1, 1)\n",
    "    dist_norm = (dist_m.astype(np.float32) / 300.0).reshape(-1, 1)\n",
    "    features = np.concatenate([xyz, refl_norm, dist_norm], axis=1)\n",
    "    del valid, dist_m, az_rad, el_rad, cos_el, x, y, z\n",
    "    return xyz, features\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_frame(model, features_np, device, chunk_size=65536):\n",
    "    \"\"\"Chunked inference — max chunk_size points per forward pass.\"\"\"\n",
    "    n = len(features_np)\n",
    "    predictions = np.zeros(n, dtype=np.int64)\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk = features_np[start:end]\n",
    "        pad_to = max(len(chunk), 128)\n",
    "        if len(chunk) < pad_to:\n",
    "            padded = np.zeros((pad_to, chunk.shape[1]), dtype=np.float32)\n",
    "            padded[:len(chunk)] = chunk\n",
    "        else:\n",
    "            padded = chunk\n",
    "        tensor = torch.from_numpy(padded).unsqueeze(0).to(device)\n",
    "        logits = model(tensor)\n",
    "        preds = logits[0, :len(chunk)].argmax(dim=-1).cpu().numpy()\n",
    "        predictions[start:end] = preds\n",
    "        del tensor, logits, preds\n",
    "    return predictions\n",
    "\n",
    "print(\"Reader + inference functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering + Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_oriented_bbox(points_m):\n",
    "    \"\"\"PCA-oriented bounding box.\"\"\"\n",
    "    center_xyz = points_m.mean(axis=0)\n",
    "    centered = points_m - center_xyz\n",
    "    cov = np.cov(centered.T)\n",
    "    if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "        mins = points_m.min(axis=0)\n",
    "        maxs = points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        mins = points_m.min(axis=0)\n",
    "        maxs = points_m.max(axis=0)\n",
    "        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "    projected = centered @ eigenvectors\n",
    "    mins = projected.min(axis=0)\n",
    "    maxs = projected.max(axis=0)\n",
    "    dimensions = maxs - mins\n",
    "    box_center_pca = (mins + maxs) / 2.0\n",
    "    center_xyz = center_xyz + eigenvectors @ box_center_pca\n",
    "    axis1_xy = eigenvectors[:2, 0]\n",
    "    yaw = np.arctan2(axis1_xy[1], axis1_xy[0])\n",
    "    return {\"center_xyz\": center_xyz, \"dimensions\": dimensions, \"yaw\": float(yaw)}\n",
    "\n",
    "\n",
    "def cluster_class_points(points_m, class_id, max_points=10000):\n",
    "    \"\"\"DBSCAN clustering for a single class.\"\"\"\n",
    "    params = DBSCAN_PARAMS[class_id]\n",
    "    eps, min_samples = params[\"eps\"], params[\"min_samples\"]\n",
    "    if len(points_m) < min_samples:\n",
    "        return []\n",
    "    full_points = points_m\n",
    "    if len(points_m) > max_points:\n",
    "        idx = np.random.choice(len(points_m), max_points, replace=False)\n",
    "        points_m = points_m[idx]\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"ball_tree\").fit_predict(points_m)\n",
    "    if len(full_points) > max_points:\n",
    "        from sklearn.neighbors import BallTree\n",
    "        sampled_mask = labels >= 0\n",
    "        if sampled_mask.sum() == 0:\n",
    "            return []\n",
    "        tree = BallTree(points_m[sampled_mask])\n",
    "        _, indices = tree.query(full_points, k=1)\n",
    "        full_labels = labels[sampled_mask][indices.ravel()]\n",
    "        dists = np.linalg.norm(full_points - points_m[sampled_mask][indices.ravel()], axis=1)\n",
    "        full_labels[dists > eps * 2] = -1\n",
    "        labels = full_labels\n",
    "        points_m = full_points\n",
    "    clusters = []\n",
    "    for lbl in sorted(set(labels) - {-1}):\n",
    "        clusters.append(points_m[labels == lbl])\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def merge_cable_clusters(clusters):\n",
    "    \"\"\"Merge collinear cable clusters.\"\"\"\n",
    "    if len(clusters) <= 1:\n",
    "        return clusters\n",
    "    angle_thresh = np.radians(CABLE_MERGE_ANGLE_DEG)\n",
    "    gap_thresh = CABLE_MERGE_GAP_M\n",
    "    infos = []\n",
    "    for pts in clusters:\n",
    "        if len(pts) < 4:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        centered = pts - pts.mean(axis=0)\n",
    "        cov = np.cov(centered.T)\n",
    "        if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        try:\n",
    "            eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "        except np.linalg.LinAlgError:\n",
    "            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n",
    "            continue\n",
    "        axis1 = eigvecs[:, eigvals.argsort()[::-1][0]]\n",
    "        if axis1[0] < 0:\n",
    "            axis1 = -axis1\n",
    "        infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": axis1})\n",
    "    merged_flags = [False] * len(infos)\n",
    "    result = []\n",
    "    for i in range(len(infos)):\n",
    "        if merged_flags[i]:\n",
    "            continue\n",
    "        current = infos[i][\"points\"]\n",
    "        if infos[i][\"axis1\"] is not None:\n",
    "            for j in range(i + 1, len(infos)):\n",
    "                if merged_flags[j] or infos[j][\"axis1\"] is None:\n",
    "                    continue\n",
    "                dot = min(abs(np.dot(infos[i][\"axis1\"], infos[j][\"axis1\"])), 1.0)\n",
    "                if np.arccos(dot) > angle_thresh:\n",
    "                    continue\n",
    "                cdist = np.linalg.norm(infos[i][\"center\"] - infos[j][\"center\"])\n",
    "                ext_i = np.abs((infos[i][\"points\"] - infos[i][\"center\"]) @ infos[i][\"axis1\"]).max()\n",
    "                ext_j = np.abs((infos[j][\"points\"] - infos[j][\"center\"]) @ infos[j][\"axis1\"]).max()\n",
    "                if cdist - ext_i - ext_j <= gap_thresh:\n",
    "                    current = np.vstack([current, infos[j][\"points\"]])\n",
    "                    merged_flags[j] = True\n",
    "        result.append(current)\n",
    "    return result\n",
    "\n",
    "\n",
    "def predictions_to_boxes(xyz_m, predictions):\n",
    "    \"\"\"Convert per-point predictions to bounding boxes.\"\"\"\n",
    "    boxes = []\n",
    "    for cid in range(1, 5):\n",
    "        mask = predictions == cid\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        class_points = xyz_m[mask]\n",
    "        clusters = cluster_class_points(class_points, cid)\n",
    "        if cid == 2 and len(clusters) > 1:\n",
    "            clusters = merge_cable_clusters(clusters)\n",
    "        for pts in clusters:\n",
    "            if len(pts) < 3:\n",
    "                continue\n",
    "            bbox = pca_oriented_bbox(pts)\n",
    "            boxes.append({\n",
    "                \"center_xyz\": bbox[\"center_xyz\"],\n",
    "                \"dimensions\": bbox[\"dimensions\"],\n",
    "                \"yaw\": bbox[\"yaw\"],\n",
    "                \"class_id\": cid,\n",
    "                \"class_label\": CLASS_LABELS_CSV[cid],\n",
    "                \"num_points\": len(pts),\n",
    "            })\n",
    "    return boxes\n",
    "\n",
    "print(\"Clustering + bbox functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SELECT INPUT FILES ===\n",
    "# For evaluation: point to the eval data directory\n",
    "# For testing: use a single training scene\n",
    "\n",
    "INPUT_DIR = DATA_DIR  # change to eval dir when ready\n",
    "h5_files = sorted(glob.glob(os.path.join(INPUT_DIR, \"*.h5\")))\n",
    "print(f\"Found {len(h5_files)} HDF5 files:\")\n",
    "for f in h5_files:\n",
    "    print(f\"  {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN ON ONE SCENE (for testing) ===\n",
    "# Change to loop over all files for final evaluation\n",
    "\n",
    "h5_path = os.path.join(DATA_DIR, \"scene_8.h5\")  # validation scene\n",
    "scene_name = \"scene_8\"\n",
    "output_csv = os.path.join(OUTPUT_DIR, f\"{scene_name}.csv\")\n",
    "\n",
    "print(f\"Processing {scene_name}...\")\n",
    "t0 = time.time()\n",
    "\n",
    "# Frame boundaries\n",
    "frames_info = get_frame_boundaries(h5_path)\n",
    "n_frames = len(frames_info)\n",
    "print(f\"{n_frames} frames found ({time.time()-t0:.1f}s)\")\n",
    "\n",
    "# Write CSV\n",
    "with open(output_csv, \"w\") as f:\n",
    "    f.write(CSV_HEADER)\n",
    "\n",
    "total_boxes = 0\n",
    "class_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "# Store last frame for visualization\n",
    "last_xyz = None\n",
    "last_preds = None\n",
    "last_boxes = None\n",
    "\n",
    "for idx in range(n_frames):\n",
    "    start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n",
    "\n",
    "    xyz_m, features = read_frame_for_inference(h5_path, start, end)\n",
    "    if len(xyz_m) == 0:\n",
    "        continue\n",
    "\n",
    "    predictions = predict_frame(model, features, device, chunk_size=CHUNK_SIZE)\n",
    "    del features\n",
    "\n",
    "    boxes = predictions_to_boxes(xyz_m, predictions)\n",
    "\n",
    "    if boxes:\n",
    "        lines = []\n",
    "        for box in boxes:\n",
    "            c = box[\"center_xyz\"]\n",
    "            d = box[\"dimensions\"]\n",
    "            lines.append(\n",
    "                f\"{ego_x},{ego_y},{ego_z},{ego_yaw},\"\n",
    "                f\"{c[0]:.4f},{c[1]:.4f},{c[2]:.4f},\"\n",
    "                f\"{d[0]:.4f},{d[1]:.4f},{d[2]:.4f},\"\n",
    "                f\"{box['yaw']:.4f},\"\n",
    "                f\"{box['class_id']},{box['class_label']}\\n\"\n",
    "            )\n",
    "        with open(output_csv, \"a\") as f:\n",
    "            f.writelines(lines)\n",
    "        total_boxes += len(boxes)\n",
    "        for box in boxes:\n",
    "            class_counts[box[\"class_id\"]] += 1\n",
    "\n",
    "    # Keep last frame for viz\n",
    "    if idx == n_frames - 1:\n",
    "        last_xyz = xyz_m.copy()\n",
    "        last_preds = predictions.copy()\n",
    "        last_boxes = boxes\n",
    "\n",
    "    del xyz_m, predictions, boxes\n",
    "    gc.collect()\n",
    "\n",
    "    if (idx + 1) % 10 == 0 or idx == n_frames - 1:\n",
    "        print(f\"  {idx+1}/{n_frames} frames, {total_boxes} boxes\")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nDONE — {total_boxes} boxes from {n_frames} frames in {elapsed:.0f}s ({elapsed/60:.1f} min)\")\n",
    "print(f\"Avg: {elapsed/n_frames:.2f}s/frame, {total_boxes/n_frames:.1f} boxes/frame\")\n",
    "print(f\"Per class: \" + \", \".join(f\"{CLASS_NAMES[c]}={class_counts[c]}\" for c in range(1, 5)))\n",
    "print(f\"Output: {output_csv}\")\n",
    "\n",
    "del frames_info\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "CLASS_COLORS_PLOT = {\n",
    "    0: [0.7, 0.7, 0.7],  # background — gray\n",
    "    1: [0.15, 0.09, 0.71],  # antenna — blue\n",
    "    2: [0.69, 0.52, 0.18],  # cable — brown\n",
    "    3: [0.51, 0.32, 0.38],  # electric_pole — mauve\n",
    "    4: [0.26, 0.52, 0.04],  # wind_turbine — green\n",
    "}\n",
    "\n",
    "if last_xyz is not None:\n",
    "    # Subsample for plotting\n",
    "    n_plot = min(50000, len(last_xyz))\n",
    "    idx_plot = np.random.choice(len(last_xyz), n_plot, replace=False)\n",
    "\n",
    "    colors = np.array([CLASS_COLORS_PLOT[p] for p in last_preds[idx_plot]])\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "    # Top-down view (XY)\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.scatter(last_xyz[idx_plot, 0], last_xyz[idx_plot, 1],\n",
    "                c=colors, s=0.3, alpha=0.5)\n",
    "    ax1.set_xlabel(\"X (m)\"); ax1.set_ylabel(\"Y (m)\")\n",
    "    ax1.set_title(f\"Top-down — {scene_name} last frame\")\n",
    "    ax1.set_aspect(\"equal\")\n",
    "\n",
    "    # Mark bounding box centers\n",
    "    if last_boxes:\n",
    "        for box in last_boxes:\n",
    "            c = box[\"center_xyz\"]\n",
    "            color = CLASS_COLORS_PLOT[box[\"class_id\"]]\n",
    "            ax1.plot(c[0], c[1], 'x', color=color, markersize=10, markeredgewidth=2)\n",
    "            ax1.annotate(box[\"class_label\"], (c[0], c[1]),\n",
    "                         fontsize=7, color=color, ha='center', va='bottom')\n",
    "\n",
    "    # Side view (XZ)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(last_xyz[idx_plot, 0], last_xyz[idx_plot, 2],\n",
    "                c=colors, s=0.3, alpha=0.5)\n",
    "    ax2.set_xlabel(\"X (m)\"); ax2.set_ylabel(\"Z (m)\")\n",
    "    ax2.set_title(f\"Side view — {scene_name} last frame\")\n",
    "\n",
    "    if last_boxes:\n",
    "        for box in last_boxes:\n",
    "            c = box[\"center_xyz\"]\n",
    "            color = CLASS_COLORS_PLOT[box[\"class_id\"]]\n",
    "            ax2.plot(c[0], c[2], 'x', color=color, markersize=10, markeredgewidth=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    print(\"No frame data for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(output_csv)\n",
    "print(f\"Output CSV: {output_csv}\")\n",
    "print(f\"Total rows (boxes): {len(df)}\")\n",
    "print(f\"Unique frames: {df[['ego_x','ego_y','ego_z','ego_yaw']].drop_duplicates().shape[0]}\")\n",
    "print(f\"\\nBoxes per class:\")\n",
    "print(df['class_label'].value_counts())\n",
    "print(f\"\\nBbox size stats (m):\")\n",
    "for col in ['bbox_width', 'bbox_length', 'bbox_height']:\n",
    "    print(f\"  {col}: mean={df[col].mean():.2f}, median={df[col].median():.2f}, max={df[col].max():.2f}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Evaluation Run (all files)\n",
    "\n",
    "Uncomment and run when evaluation files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FULL EVALUATION RUN ===\n",
    "# Uncomment when eval files arrive (2 scenes × 4 densities = 8 files)\n",
    "\n",
    "# EVAL_DIR = f\"{DRIVE_BASE}/eval_data\"  # <-- adjust path\n",
    "# eval_files = sorted(glob.glob(os.path.join(EVAL_DIR, \"*.h5\")))\n",
    "# print(f\"Eval files: {len(eval_files)}\")\n",
    "#\n",
    "# for h5_path in eval_files:\n",
    "#     scene_name = os.path.splitext(os.path.basename(h5_path))[0]\n",
    "#     output_csv = os.path.join(OUTPUT_DIR, f\"{scene_name}.csv\")\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Processing {scene_name}...\")\n",
    "#     t0 = time.time()\n",
    "#\n",
    "#     frames_info = get_frame_boundaries(h5_path)\n",
    "#     n_frames = len(frames_info)\n",
    "#     with open(output_csv, \"w\") as f:\n",
    "#         f.write(CSV_HEADER)\n",
    "#\n",
    "#     scene_boxes = 0\n",
    "#     for idx in range(n_frames):\n",
    "#         start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n",
    "#         xyz_m, features = read_frame_for_inference(h5_path, start, end)\n",
    "#         if len(xyz_m) == 0:\n",
    "#             continue\n",
    "#         predictions = predict_frame(model, features, device, chunk_size=CHUNK_SIZE)\n",
    "#         del features\n",
    "#         boxes = predictions_to_boxes(xyz_m, predictions)\n",
    "#         del xyz_m, predictions\n",
    "#         if boxes:\n",
    "#             lines = []\n",
    "#             for box in boxes:\n",
    "#                 c, d = box[\"center_xyz\"], box[\"dimensions\"]\n",
    "#                 lines.append(\n",
    "#                     f\"{ego_x},{ego_y},{ego_z},{ego_yaw},\"\n",
    "#                     f\"{c[0]:.4f},{c[1]:.4f},{c[2]:.4f},\"\n",
    "#                     f\"{d[0]:.4f},{d[1]:.4f},{d[2]:.4f},\"\n",
    "#                     f\"{box['yaw']:.4f},\"\n",
    "#                     f\"{box['class_id']},{box['class_label']}\\n\"\n",
    "#                 )\n",
    "#             with open(output_csv, \"a\") as f:\n",
    "#                 f.writelines(lines)\n",
    "#             scene_boxes += len(boxes)\n",
    "#         del boxes; gc.collect()\n",
    "#         if (idx + 1) % 10 == 0:\n",
    "#             print(f\"  {idx+1}/{n_frames} frames, {scene_boxes} boxes\")\n",
    "#\n",
    "#     print(f\"DONE — {scene_boxes} boxes in {time.time()-t0:.0f}s\")\n",
    "#     del frames_info; gc.collect()\n",
    "#\n",
    "# print(\"\\nAll eval files processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
