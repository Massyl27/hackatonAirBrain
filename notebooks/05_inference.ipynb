{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 05 — Inference Pipeline (v6 — D-Day Ready)\n\n**Notebook Colab GPU** pour l'inference jour J.\n\n**Améliorations v6 :**\n- class_ID corrigé : 0,1,2,3 (pas 1,2,3,4)\n- class_label : \"Electric Pole\", \"Wind Turbine\" (majuscules)\n- Box confidence filtering (seuil 0.6)\n- DBSCAN resserré + min_points rehaussés\n- TTA optionnel (4x rotation Z)\n\n**Usage jour J :**\n1. Uploader les fichiers d'évaluation sur Drive dans `eval_data/`\n2. Lancer toutes les cellules (Runtime > Run all)\n3. Les CSVs sont dans `outputs/pred_eval/`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\n!pip install -q h5py scikit-learn"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import gc\nimport glob\nimport os\nimport time\n\nimport h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import BallTree\n\n# ==========================================================================\n# PATHS — Modifier ici pour le jour J\n# ==========================================================================\nDRIVE_BASE = \"/content/drive/MyDrive/airbus_hackathon\"\n\n# --- JOUR J : décommenter la ligne EVAL et commenter TRAINING ---\nINPUT_DIR = f\"{DRIVE_BASE}/data\"                    # TRAINING (test)\n# INPUT_DIR = f\"{DRIVE_BASE}/eval_data\"             # JOUR J (évaluation)\n\nOUTPUT_DIR = f\"{DRIVE_BASE}/outputs/pred_v6\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Checkpoint (auto-select best)\nCKPT_V5 = f\"{DRIVE_BASE}/checkpoints_v5/best_model_v5.pt\"\nCKPT_V4 = f\"{DRIVE_BASE}/checkpoints_v4/best_model_v4.pt\"\nCKPT_PATH = CKPT_V5 if os.path.exists(CKPT_V5) else CKPT_V4\n\n# ==========================================================================\n# OPTIONS\n# ==========================================================================\nUSE_TTA = False          # True = 4x rotation averaging (slower, more robust)\nSINGLE_SCENE = \"scene_8\" # None = traiter TOUS les fichiers .h5 du dossier\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Checkpoint: {CKPT_PATH}\")\nprint(f\"Input dir:  {INPUT_DIR}\")\nprint(f\"Output dir: {OUTPUT_DIR}\")\nprint(f\"Device:     {device}\")\nprint(f\"TTA:        {'ON (4x rotations)' if USE_TTA else 'OFF'}\")\nprint(f\"Mode:       {'Single scene (' + SINGLE_SCENE + ')' if SINGLE_SCENE else 'ALL scenes'}\")\nif torch.cuda.is_available():\n    print(f\"GPU:        {torch.cuda.get_device_name()}\")\n    print(f\"VRAM:       {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Config (v6 — calibrated on scene_8 validation)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "NUM_CLASSES = 5\nIN_CHANNELS = 5  # x, y, z, reflectivity, norm_distance\nCHUNK_SIZE = 65536  # points per forward pass\n\nCLASS_NAMES = {0: \"background\", 1: \"antenna\", 2: \"cable\", 3: \"electric_pole\", 4: \"wind_turbine\"}\n\n# Airbus spec labels — capitalization matters!\nCLASS_LABELS_CSV = {1: \"Antenna\", 2: \"Cable\", 3: \"Electric Pole\", 4: \"Wind Turbine\"}\n\n# Internal class_id (1-4) → Airbus class_ID (0-3)\nCLASS_ID_TO_AIRBUS = {1: 0, 2: 1, 3: 2, 4: 3}\n\n# DBSCAN — tightened for noisy predictions (v6)\nDBSCAN_PARAMS = {\n    1: {\"eps\": 2.0, \"min_samples\": 15},    # Antenna\n    2: {\"eps\": 5.0, \"min_samples\": 8},     # Cable\n    3: {\"eps\": 2.0, \"min_samples\": 12},    # Electric pole\n    4: {\"eps\": 5.0, \"min_samples\": 25},    # Wind turbine\n}\n\nCABLE_MERGE_ANGLE_DEG = 15.0\nCABLE_MERGE_GAP_M = 10.0\n\n# Post-processing thresholds (v6 — calibrated on scene_8)\nCONFIDENCE_THRESHOLD = 0.3       # per-point softmax filter\nBOX_CONFIDENCE_THRESHOLD = 0.6   # per-box mean confidence filter\nMIN_POINTS_PER_BOX = {1: 15, 2: 5, 3: 10, 4: 25}\nMAX_DIM_PER_CLASS = {1: 200.0, 2: 400.0, 3: 100.0, 4: 250.0}\nNMS_IOU_THRESHOLD = 0.3\n\nCSV_HEADER = (\"ego_x,ego_y,ego_z,ego_yaw,\"\n              \"bbox_center_x,bbox_center_y,bbox_center_z,\"\n              \"bbox_width,bbox_length,bbox_height,\"\n              \"bbox_yaw,\"\n              \"class_ID,class_label\\n\")\n\nprint(\"Config v6 loaded.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Model + Load checkpoint"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SharedMLP(nn.Module):\n    def __init__(self, in_ch, out_ch, bn=True):\n        super().__init__()\n        self.conv = nn.Conv1d(in_ch, out_ch, 1, bias=not bn)\n        self.bn = nn.BatchNorm1d(out_ch) if bn else None\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn:\n            x = self.bn(x)\n        return F.relu(x, inplace=True)\n\n\nclass PointNetSegV4(nn.Module):\n    \"\"\"PointNet v4 segmentation — multi-scale skips, ~1.88M params.\"\"\"\n    def __init__(self, in_channels=5, num_classes=5):\n        super().__init__()\n        self.enc1 = SharedMLP(in_channels, 64)\n        self.enc2 = SharedMLP(64, 128)\n        self.enc3 = SharedMLP(128, 256)\n        self.enc4 = SharedMLP(256, 512)\n        self.enc5 = SharedMLP(512, 1024)\n        self.seg1 = SharedMLP(64 + 128 + 256 + 512 + 1024, 512)\n        self.seg2 = SharedMLP(512, 256)\n        self.seg3 = SharedMLP(256, 128)\n        self.dropout1 = nn.Dropout(0.4)\n        self.dropout2 = nn.Dropout(0.3)\n        self.head = nn.Conv1d(128, num_classes, 1)\n\n    def forward(self, x):\n        B, N, _ = x.shape\n        x = x.transpose(1, 2)\n        e1 = self.enc1(x)\n        e2 = self.enc2(e1)\n        e3 = self.enc3(e2)\n        e4 = self.enc4(e3)\n        e5 = self.enc5(e4)\n        g = e5.max(dim=2, keepdim=True)[0].expand(-1, -1, N)\n        seg = torch.cat([e1, e2, e3, e4, g], dim=1)\n        seg = self.seg1(seg)\n        seg = self.dropout1(seg)\n        seg = self.seg2(seg)\n        seg = self.dropout2(seg)\n        seg = self.seg3(seg)\n        seg = self.head(seg)\n        return seg.transpose(1, 2)\n\n\n# Load model\nprint(f\"Loading {CKPT_PATH}...\")\nmodel = PointNetSegV4(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES).to(device)\nckpt = torch.load(CKPT_PATH, map_location=device, weights_only=False)\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.eval()\n\nn_params = sum(p.numel() for p in model.parameters())\nprint(f\"PointNetSegV4: {n_params:,} params on {device}\")\nif \"val_obstacle_miou\" in ckpt:\n    print(f\"Epoch {ckpt.get('epoch', '?')}, val obstacle mIoU={ckpt['val_obstacle_miou']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HDF5 Reader + Inference + TTA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === HDF5 READER ===\n\ndef get_frame_boundaries(h5_path, dataset_name=\"lidar_points\", chunk_size=2_000_000):\n    change_indices = []\n    with h5py.File(h5_path, \"r\") as f:\n        ds = f[dataset_name]\n        n = ds.shape[0]\n        prev_last_pose = None\n        for offset in range(0, n, chunk_size):\n            end = min(offset + chunk_size, n)\n            chunk = ds[offset:end]\n            ex, ey, ez, eyaw = chunk[\"ego_x\"], chunk[\"ego_y\"], chunk[\"ego_z\"], chunk[\"ego_yaw\"]\n            if prev_last_pose is not None:\n                cur_first = (int(ex[0]), int(ey[0]), int(ez[0]), int(eyaw[0]))\n                if cur_first != prev_last_pose:\n                    change_indices.append(offset)\n            changes = np.where(\n                (np.diff(ex) != 0) | (np.diff(ey) != 0) |\n                (np.diff(ez) != 0) | (np.diff(eyaw) != 0)\n            )[0] + 1\n            for c in changes:\n                change_indices.append(offset + int(c))\n            prev_last_pose = (int(ex[-1]), int(ey[-1]), int(ez[-1]), int(eyaw[-1]))\n            del chunk, ex, ey, ez, eyaw; gc.collect()\n    starts = [0] + change_indices\n    ends = change_indices + [n]\n    frames = []\n    with h5py.File(h5_path, \"r\") as f:\n        ds = f[dataset_name]\n        for s, e in zip(starts, ends):\n            row = ds[s]\n            frames.append((s, e, int(row[\"ego_x\"]), int(row[\"ego_y\"]),\n                           int(row[\"ego_z\"]), int(row[\"ego_yaw\"])))\n    return frames\n\n\ndef read_frame_for_inference(h5_path, start, end, dataset_name=\"lidar_points\"):\n    with h5py.File(h5_path, \"r\") as f:\n        chunk = f[dataset_name][start:end]\n    valid = chunk[chunk[\"distance_cm\"] > 0]\n    del chunk\n    dist_m = valid[\"distance_cm\"].astype(np.float64) / 100.0\n    az_rad = np.radians(valid[\"azimuth_raw\"].astype(np.float64) / 100.0)\n    el_rad = np.radians(valid[\"elevation_raw\"].astype(np.float64) / 100.0)\n    cos_el = np.cos(el_rad)\n    x = dist_m * cos_el * np.cos(az_rad)\n    y = -dist_m * cos_el * np.sin(az_rad)\n    z = dist_m * np.sin(el_rad)\n    xyz = np.column_stack((x, y, z)).astype(np.float32)\n    refl_norm = (valid[\"reflectivity\"].astype(np.float32) / 255.0).reshape(-1, 1)\n    dist_norm = (dist_m.astype(np.float32) / 300.0).reshape(-1, 1)\n    features = np.concatenate([xyz, refl_norm, dist_norm], axis=1)\n    del valid, dist_m, az_rad, el_rad, cos_el, x, y, z\n    return xyz, features\n\n\n# === INFERENCE ===\n\n@torch.no_grad()\ndef predict_frame_standard(model, features_np, device, chunk_size=CHUNK_SIZE):\n    \"\"\"Standard inference — returns (predictions, confidences).\"\"\"\n    n = len(features_np)\n    predictions = np.zeros(n, dtype=np.int64)\n    confidences = np.zeros(n, dtype=np.float32)\n    for start in range(0, n, chunk_size):\n        end = min(start + chunk_size, n)\n        chunk = features_np[start:end]\n        pad_to = max(len(chunk), 128)\n        if len(chunk) < pad_to:\n            padded = np.zeros((pad_to, chunk.shape[1]), dtype=np.float32)\n            padded[:len(chunk)] = chunk\n        else:\n            padded = chunk\n        tensor = torch.from_numpy(padded).unsqueeze(0).to(device)\n        logits = model(tensor)\n        probs = F.softmax(logits[0, :len(chunk)], dim=-1)\n        conf, preds = probs.max(dim=-1)\n        preds, conf = preds.cpu().numpy(), conf.cpu().numpy()\n        low_conf = (preds > 0) & (conf < CONFIDENCE_THRESHOLD)\n        preds[low_conf] = 0\n        predictions[start:end] = preds\n        confidences[start:end] = conf\n        del tensor, logits, probs, preds, conf\n    return predictions, confidences\n\n\n# === TTA ===\n\n@torch.no_grad()\ndef _get_logits_chunked(model, features_np, device, chunk_size=CHUNK_SIZE):\n    n = len(features_np)\n    all_logits = np.zeros((n, NUM_CLASSES), dtype=np.float32)\n    for start in range(0, n, chunk_size):\n        end = min(start + chunk_size, n)\n        chunk = features_np[start:end]\n        pad_to = max(len(chunk), 128)\n        if len(chunk) < pad_to:\n            padded = np.zeros((pad_to, chunk.shape[1]), dtype=np.float32)\n            padded[:len(chunk)] = chunk\n        else:\n            padded = chunk\n        tensor = torch.from_numpy(padded).unsqueeze(0).to(device)\n        logits = model(tensor)\n        all_logits[start:end] = logits[0, :len(chunk)].cpu().numpy()\n        del tensor, logits\n    return all_logits\n\n\ndef _rotate_features_z(features_np, angle_rad):\n    rotated = features_np.copy()\n    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n    x, y = features_np[:, 0], features_np[:, 1]\n    rotated[:, 0] = cos_a * x - sin_a * y\n    rotated[:, 1] = sin_a * x + cos_a * y\n    return rotated\n\n\n@torch.no_grad()\ndef predict_frame_tta(model, features_np, device, chunk_size=CHUNK_SIZE):\n    \"\"\"TTA: average logits over 4 Z-rotations. Returns (predictions, confidences).\"\"\"\n    angles = [0, np.pi / 2, np.pi, 3 * np.pi / 2]\n    n = len(features_np)\n    avg_logits = np.zeros((n, NUM_CLASSES), dtype=np.float32)\n    for angle in angles:\n        feats = features_np if angle == 0 else _rotate_features_z(features_np, angle)\n        avg_logits += _get_logits_chunked(model, feats, device, chunk_size)\n        if angle != 0: del feats\n    avg_logits /= len(angles)\n    probs = np.exp(avg_logits - avg_logits.max(axis=1, keepdims=True))\n    probs /= probs.sum(axis=1, keepdims=True)\n    predictions = probs.argmax(axis=1).astype(np.int64)\n    confidences = probs[np.arange(n), predictions].astype(np.float32)\n    low_conf = (predictions > 0) & (confidences < CONFIDENCE_THRESHOLD)\n    predictions[low_conf] = 0\n    del avg_logits, probs\n    return predictions, confidences\n\n\n# Select predict function\npredict_frame = predict_frame_tta if USE_TTA else predict_frame_standard\nprint(f\"Functions defined. Predict: {'TTA' if USE_TTA else 'standard'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Clustering + Bounding Boxes + Post-processing (v6)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def pca_oriented_bbox(points_m):\n    center_xyz = points_m.mean(axis=0)\n    centered = points_m - center_xyz\n    cov = np.cov(centered.T)\n    if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n        mins, maxs = points_m.min(axis=0), points_m.max(axis=0)\n        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n    try:\n        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n    except np.linalg.LinAlgError:\n        mins, maxs = points_m.min(axis=0), points_m.max(axis=0)\n        return {\"center_xyz\": (mins + maxs) / 2.0, \"dimensions\": maxs - mins, \"yaw\": 0.0}\n    order = eigenvalues.argsort()[::-1]\n    eigenvectors = eigenvectors[:, order]\n    projected = centered @ eigenvectors\n    mins, maxs = projected.min(axis=0), projected.max(axis=0)\n    dimensions = maxs - mins\n    box_center_pca = (mins + maxs) / 2.0\n    center_xyz = center_xyz + eigenvectors @ box_center_pca\n    yaw = np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0])\n    return {\"center_xyz\": center_xyz, \"dimensions\": dimensions, \"yaw\": float(yaw)}\n\n\ndef cluster_class_points(points_m, class_id, max_points=10000):\n    params = DBSCAN_PARAMS[class_id]\n    eps, min_samples = params[\"eps\"], params[\"min_samples\"]\n    if len(points_m) < min_samples:\n        return []\n    full_points = points_m\n    if len(points_m) > max_points:\n        idx = np.random.choice(len(points_m), max_points, replace=False)\n        points_m = points_m[idx]\n    labels = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"ball_tree\").fit_predict(points_m)\n    if len(full_points) > max_points:\n        sampled_mask = labels >= 0\n        if sampled_mask.sum() == 0:\n            return []\n        tree = BallTree(points_m[sampled_mask])\n        _, indices = tree.query(full_points, k=1)\n        full_labels = labels[sampled_mask][indices.ravel()]\n        dists = np.linalg.norm(full_points - points_m[sampled_mask][indices.ravel()], axis=1)\n        full_labels[dists > eps * 2] = -1\n        labels = full_labels\n        points_m = full_points\n    clusters = []\n    for lbl in sorted(set(labels) - {-1}):\n        clusters.append(points_m[labels == lbl])\n    return clusters\n\n\ndef merge_cable_clusters(clusters):\n    if len(clusters) <= 1:\n        return clusters\n    angle_thresh = np.radians(CABLE_MERGE_ANGLE_DEG)\n    gap_thresh = CABLE_MERGE_GAP_M\n    infos = []\n    for pts in clusters:\n        if len(pts) < 4:\n            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n            continue\n        centered = pts - pts.mean(axis=0)\n        cov = np.cov(centered.T)\n        if np.any(np.isnan(cov)) or np.any(np.isinf(cov)):\n            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n            continue\n        try:\n            eigvals, eigvecs = np.linalg.eigh(cov)\n        except np.linalg.LinAlgError:\n            infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": None})\n            continue\n        axis1 = eigvecs[:, eigvals.argsort()[::-1][0]]\n        if axis1[0] < 0: axis1 = -axis1\n        infos.append({\"points\": pts, \"center\": pts.mean(axis=0), \"axis1\": axis1})\n    merged_flags = [False] * len(infos)\n    result = []\n    for i in range(len(infos)):\n        if merged_flags[i]: continue\n        current = infos[i][\"points\"]\n        if infos[i][\"axis1\"] is not None:\n            for j in range(i + 1, len(infos)):\n                if merged_flags[j] or infos[j][\"axis1\"] is None: continue\n                dot = min(abs(np.dot(infos[i][\"axis1\"], infos[j][\"axis1\"])), 1.0)\n                if np.arccos(dot) > angle_thresh: continue\n                cdist = np.linalg.norm(infos[i][\"center\"] - infos[j][\"center\"])\n                ext_i = np.abs((infos[i][\"points\"] - infos[i][\"center\"]) @ infos[i][\"axis1\"]).max()\n                ext_j = np.abs((infos[j][\"points\"] - infos[j][\"center\"]) @ infos[j][\"axis1\"]).max()\n                if cdist - ext_i - ext_j <= gap_thresh:\n                    current = np.vstack([current, infos[j][\"points\"]])\n                    merged_flags[j] = True\n        result.append(current)\n    return result\n\n\ndef filter_boxes(boxes):\n    return [b for b in boxes\n            if b[\"num_points\"] >= MIN_POINTS_PER_BOX.get(b[\"class_id\"], 3)\n            and max(b[\"dimensions\"]) <= MAX_DIM_PER_CLASS.get(b[\"class_id\"], 500.0)]\n\n\ndef _box_iou_3d(a, b):\n    ca, da, cb, db = a[\"center_xyz\"], a[\"dimensions\"], b[\"center_xyz\"], b[\"dimensions\"]\n    ha, hb = da / 2.0, db / 2.0\n    overlap = np.maximum(0, np.minimum(ca + ha, cb + hb) - np.maximum(ca - ha, cb - hb))\n    inter = overlap[0] * overlap[1] * overlap[2]\n    union = da[0]*da[1]*da[2] + db[0]*db[1]*db[2] - inter\n    return inter / union if union > 0 else 0.0\n\n\ndef nms_boxes(boxes, iou_threshold=NMS_IOU_THRESHOLD):\n    if len(boxes) <= 1: return boxes\n    by_class = {}\n    for b in boxes: by_class.setdefault(b[\"class_id\"], []).append(b)\n    result = []\n    for cid, cb in by_class.items():\n        cb.sort(key=lambda b: b[\"num_points\"], reverse=True)\n        suppressed = [False] * len(cb)\n        for i in range(len(cb)):\n            if suppressed[i]: continue\n            result.append(cb[i])\n            for j in range(i+1, len(cb)):\n                if not suppressed[j] and _box_iou_3d(cb[i], cb[j]) > iou_threshold:\n                    suppressed[j] = True\n    return result\n\n\ndef predictions_to_boxes(xyz_m, predictions, confidences=None):\n    \"\"\"Full pipeline: cluster → PCA bbox → confidence filter → size filter → NMS.\"\"\"\n    boxes = []\n    for cid in range(1, 5):\n        mask = predictions == cid\n        if mask.sum() == 0: continue\n        class_points = xyz_m[mask]\n        class_conf = confidences[mask] if confidences is not None else None\n        clusters = cluster_class_points(class_points, cid)\n        if cid == 2 and len(clusters) > 1:\n            clusters = merge_cable_clusters(clusters)\n        # Build BallTree once per class for confidence lookup\n        conf_tree = None\n        if class_conf is not None and len(clusters) > 0:\n            conf_tree = BallTree(class_points)\n        for pts in clusters:\n            if len(pts) < 3: continue\n            box_confidence = 0.0\n            if conf_tree is not None:\n                _, indices = conf_tree.query(pts, k=1)\n                box_confidence = float(class_conf[indices.ravel()].mean())\n            bbox = pca_oriented_bbox(pts)\n            boxes.append({\n                \"center_xyz\": bbox[\"center_xyz\"], \"dimensions\": bbox[\"dimensions\"],\n                \"yaw\": bbox[\"yaw\"], \"class_id\": cid, \"class_label\": CLASS_LABELS_CSV[cid],\n                \"num_points\": len(pts), \"confidence\": box_confidence,\n            })\n    # Box confidence filter\n    if BOX_CONFIDENCE_THRESHOLD > 0:\n        boxes = [b for b in boxes if b[\"confidence\"] >= BOX_CONFIDENCE_THRESHOLD]\n    boxes = filter_boxes(boxes)\n    boxes = nms_boxes(boxes)\n    return boxes\n\n\ndef boxes_to_csv_lines(boxes, ego_x, ego_y, ego_z, ego_yaw):\n    \"\"\"Format boxes as CSV lines — Airbus deliverable format (class_ID 0-3).\"\"\"\n    lines = []\n    for box in boxes:\n        c, d = box[\"center_xyz\"], box[\"dimensions\"]\n        airbus_cid = CLASS_ID_TO_AIRBUS[box[\"class_id\"]]\n        lines.append(\n            f\"{ego_x},{ego_y},{ego_z},{ego_yaw},\"\n            f\"{c[0]:.4f},{c[1]:.4f},{c[2]:.4f},\"\n            f\"{d[0]:.4f},{d[1]:.4f},{d[2]:.4f},\"\n            f\"{box['yaw']:.4f},\"\n            f\"{airbus_cid},{box['class_label']}\\n\"\n        )\n    return lines\n\nprint(\"Clustering + post-processing v6 defined.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RUN INFERENCE"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Collect input files\nif SINGLE_SCENE:\n    h5_files = [os.path.join(INPUT_DIR, f\"{SINGLE_SCENE}.h5\")]\nelse:\n    h5_files = sorted(glob.glob(os.path.join(INPUT_DIR, \"*.h5\")))\n\nprint(f\"Files to process: {len(h5_files)}\")\nfor f in h5_files:\n    print(f\"  {os.path.basename(f)}\")\n\nassert len(h5_files) > 0, f\"No .h5 files found in {INPUT_DIR}\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === MAIN INFERENCE LOOP ===\n\ntotal_boxes = 0\ntotal_frames = 0\nt_total = time.time()\nall_scene_stats = []\n\nfor h5_path in h5_files:\n    scene_name = os.path.splitext(os.path.basename(h5_path))[0]\n    output_csv = os.path.join(OUTPUT_DIR, f\"{scene_name}.csv\")\n\n    print(f\"\\n{'='*60}\")\n    print(f\"[{scene_name}] Processing {h5_path}\")\n\n    t0 = time.time()\n    frames_info = get_frame_boundaries(h5_path)\n    n_frames = len(frames_info)\n    print(f\"[{scene_name}] {n_frames} frames ({time.time()-t0:.1f}s)\")\n\n    with open(output_csv, \"w\") as f:\n        f.write(CSV_HEADER)\n\n    scene_boxes = 0\n    class_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n\n    for idx in range(n_frames):\n        start, end, ego_x, ego_y, ego_z, ego_yaw = frames_info[idx]\n\n        xyz_m, features = read_frame_for_inference(h5_path, start, end)\n        if len(xyz_m) == 0:\n            total_frames += 1\n            continue\n\n        predictions, confidences = predict_frame(model, features, device)\n        del features\n\n        boxes = predictions_to_boxes(xyz_m, predictions, confidences)\n        del xyz_m, predictions, confidences\n\n        if boxes:\n            lines = boxes_to_csv_lines(boxes, ego_x, ego_y, ego_z, ego_yaw)\n            with open(output_csv, \"a\") as f:\n                f.writelines(lines)\n            scene_boxes += len(boxes)\n            for box in boxes:\n                class_counts[box[\"class_id\"]] += 1\n\n        del boxes; gc.collect()\n        total_frames += 1\n\n        if (idx + 1) % 10 == 0 or idx == n_frames - 1:\n            print(f\"  {idx+1}/{n_frames} frames, {scene_boxes} boxes\")\n\n    total_boxes += scene_boxes\n    elapsed_scene = time.time() - t0\n    stats = {\n        \"scene\": scene_name, \"frames\": n_frames, \"boxes\": scene_boxes,\n        \"time_s\": elapsed_scene, **{CLASS_NAMES[c]: class_counts[c] for c in range(1, 5)}\n    }\n    all_scene_stats.append(stats)\n    print(f\"[{scene_name}] DONE — {scene_boxes} boxes, {elapsed_scene:.0f}s\")\n    print(f\"  Per class: \" + \", \".join(f\"{CLASS_NAMES[c]}={class_counts[c]}\" for c in range(1, 5)))\n    print(f\"  Output: {output_csv}\")\n\n    del frames_info; gc.collect()\n\nelapsed = time.time() - t_total\nprint(f\"\\n{'='*60}\")\nprint(f\"INFERENCE COMPLETE\")\nprint(f\"Total: {total_boxes} boxes across {total_frames} frames\")\nprint(f\"Time: {elapsed:.0f}s ({elapsed/60:.1f} min)\")\nprint(f\"Avg: {elapsed/max(total_frames,1):.2f}s/frame, {total_boxes/max(total_frames,1):.1f} boxes/frame\")\nprint(f\"Output dir: {OUTPUT_DIR}\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Validation : vérifier le format CSV"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# Validate all output CSVs\nprint(\"=== CSV VALIDATION ===\\n\")\ncsv_files = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"*.csv\")))\nall_ok = True\n\nfor csv_path in csv_files:\n    name = os.path.basename(csv_path)\n    df = pd.read_csv(csv_path)\n\n    # Check header\n    expected_cols = [\"ego_x\",\"ego_y\",\"ego_z\",\"ego_yaw\",\n                     \"bbox_center_x\",\"bbox_center_y\",\"bbox_center_z\",\n                     \"bbox_width\",\"bbox_length\",\"bbox_height\",\n                     \"bbox_yaw\",\"class_ID\",\"class_label\"]\n    cols_ok = list(df.columns) == expected_cols\n\n    # Check class_ID range (must be 0-3, NOT 1-4)\n    if len(df) > 0:\n        cid_ok = set(df[\"class_ID\"].unique()).issubset({0, 1, 2, 3})\n        labels_ok = set(df[\"class_label\"].unique()).issubset({\"Antenna\", \"Cable\", \"Electric Pole\", \"Wind Turbine\"})\n    else:\n        cid_ok = True\n        labels_ok = True\n\n    ok = cols_ok and cid_ok and labels_ok\n    status = \"OK\" if ok else \"FAIL\"\n    if not ok: all_ok = False\n\n    print(f\"  {name}: {len(df)} rows, class_IDs={sorted(df['class_ID'].unique()) if len(df) else '[]'}, [{status}]\")\n    if not cols_ok: print(f\"    COLUMNS MISMATCH: {list(df.columns)}\")\n    if not cid_ok: print(f\"    CLASS_ID ERROR: found {sorted(df['class_ID'].unique())}, expected 0-3\")\n    if not labels_ok: print(f\"    LABEL ERROR: found {sorted(df['class_label'].unique())}\")\n\nprint(f\"\\n{'ALL CSVs VALID' if all_ok else 'SOME CSVs HAVE ERRORS — FIX BEFORE SUBMISSION'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\nprint(\"=== SUMMARY ===\\n\")\nprint(f\"Model: PointNetSegV4, {n_params:,} params\")\nprint(f\"Device: {device}, TTA: {'ON' if USE_TTA else 'OFF'}\")\nprint(f\"Box confidence threshold: {BOX_CONFIDENCE_THRESHOLD}\")\nprint(f\"Total time: {elapsed:.0f}s ({elapsed/60:.1f} min)\\n\")\n\nif all_scene_stats:\n    df_stats = pd.DataFrame(all_scene_stats)\n    print(df_stats.to_string(index=False))\n\nprint(f\"\\nOutput CSVs in: {OUTPUT_DIR}\")\nprint(\"\\n--- CHECKLIST JOUR J ---\")\nprint(\"[ ] Changer INPUT_DIR vers eval_data/\")\nprint(\"[ ] Mettre SINGLE_SCENE = None\")\nprint(\"[ ] Vérifier que le checkpoint est sur Drive\")\nprint(\"[ ] Runtime > Run all\")\nprint(\"[ ] Vérifier les CSVs (cellule validation)\")\nprint(\"[ ] Télécharger les CSVs et soumettre\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}